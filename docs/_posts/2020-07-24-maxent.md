---
layout: post
title: Inference of maxent models
---

Infering and benchmarking of Maxent models.

{% include post-image-gallery.html filter="maxent/" %}

### Code 
#### entropy_analysis.ipynb

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib

import sys
sys.path.append('..')
from lib import *
```


```python
L = 9
q = naminoacids
```


```python
df = pd.read_csv('data/entropies.csv', index_col=0)
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>S</th>
      <th>E</th>
      <th>F</th>
      <th>Ehuman</th>
    </tr>
    <tr>
      <th>name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Human</th>
      <td>25.853997</td>
      <td>-2.590162</td>
      <td>-28.444159</td>
      <td>-2.590162</td>
    </tr>
    <tr>
      <th>Malaria</th>
      <td>24.456549</td>
      <td>-5.282235</td>
      <td>-29.738784</td>
      <td>-2.088056</td>
    </tr>
    <tr>
      <th>Chagas</th>
      <td>25.629811</td>
      <td>-2.977678</td>
      <td>-28.607489</td>
      <td>-2.562489</td>
    </tr>
    <tr>
      <th>Tuberculosis</th>
      <td>24.926774</td>
      <td>-4.600918</td>
      <td>-29.527692</td>
      <td>-2.779992</td>
    </tr>
    <tr>
      <th>Ecoli</th>
      <td>25.818570</td>
      <td>-2.805620</td>
      <td>-28.624189</td>
      <td>-2.277082</td>
    </tr>
  </tbody>
</table>
</div>




```python
Fhuman = df.loc['Human']["F"]
```


```python
df['DKL'] = df['Ehuman']-df['E'] + df['F'] - Fhuman
df['DKL_rand'] = np.log(q)*L-df['S']
```


```python
nats_to_bits = np.log2(np.exp(1))
```


```python
plt.hist(df['S']*nats_to_bits)
plt.axvline(np.log2(q)*L, color='k')
```




    <matplotlib.lines.Line2D at 0x7f49b954e7f0>




![png](notebook_files/entropy_analysis_6_1.png)



```python
df.sort_values('S')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>S</th>
      <th>E</th>
      <th>F</th>
      <th>Ehuman</th>
      <th>DKL</th>
      <th>DKL_rand</th>
    </tr>
    <tr>
      <th>name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>HBV</th>
      <td>20.290374</td>
      <td>-5.595645</td>
      <td>-25.886019</td>
      <td>-2.412454</td>
      <td>5.741331</td>
      <td>6.671217</td>
    </tr>
    <tr>
      <th>HCV</th>
      <td>23.543850</td>
      <td>-4.021414</td>
      <td>-27.565264</td>
      <td>-2.394171</td>
      <td>2.506137</td>
      <td>3.417740</td>
    </tr>
    <tr>
      <th>HIV</th>
      <td>23.565330</td>
      <td>-3.406392</td>
      <td>-26.971722</td>
      <td>-2.101879</td>
      <td>2.776949</td>
      <td>3.396261</td>
    </tr>
    <tr>
      <th>InfluenzaA</th>
      <td>23.943078</td>
      <td>-3.242337</td>
      <td>-27.185416</td>
      <td>-1.992319</td>
      <td>2.508762</td>
      <td>3.018512</td>
    </tr>
    <tr>
      <th>DENV</th>
      <td>24.066164</td>
      <td>-3.276689</td>
      <td>-27.342853</td>
      <td>-1.953459</td>
      <td>2.424536</td>
      <td>2.895427</td>
    </tr>
    <tr>
      <th>InfluenzaB</th>
      <td>24.403003</td>
      <td>-3.243520</td>
      <td>-27.646523</td>
      <td>-2.059277</td>
      <td>1.981878</td>
      <td>2.558587</td>
    </tr>
    <tr>
      <th>Malaria</th>
      <td>24.456549</td>
      <td>-5.282235</td>
      <td>-29.738784</td>
      <td>-2.088056</td>
      <td>1.899554</td>
      <td>2.505042</td>
    </tr>
    <tr>
      <th>Ebola</th>
      <td>24.530203</td>
      <td>-3.211622</td>
      <td>-27.741825</td>
      <td>-2.166519</td>
      <td>1.747436</td>
      <td>2.431387</td>
    </tr>
    <tr>
      <th>HSV1</th>
      <td>24.893040</td>
      <td>-4.357561</td>
      <td>-29.250601</td>
      <td>-2.804701</td>
      <td>0.746418</td>
      <td>2.068550</td>
    </tr>
    <tr>
      <th>Tuberculosis</th>
      <td>24.926774</td>
      <td>-4.600918</td>
      <td>-29.527692</td>
      <td>-2.779992</td>
      <td>0.737393</td>
      <td>2.034817</td>
    </tr>
    <tr>
      <th>Lyme</th>
      <td>25.006633</td>
      <td>-4.858972</td>
      <td>-29.865605</td>
      <td>-2.398300</td>
      <td>1.039225</td>
      <td>1.954958</td>
    </tr>
    <tr>
      <th>Burkholderia</th>
      <td>25.029332</td>
      <td>-4.291638</td>
      <td>-29.320969</td>
      <td>-2.660384</td>
      <td>0.754443</td>
      <td>1.932259</td>
    </tr>
    <tr>
      <th>EBV</th>
      <td>25.091558</td>
      <td>-3.733864</td>
      <td>-28.825422</td>
      <td>-2.833468</td>
      <td>0.519133</td>
      <td>1.870033</td>
    </tr>
    <tr>
      <th>Leprosy</th>
      <td>25.228458</td>
      <td>-4.073624</td>
      <td>-29.302082</td>
      <td>-2.625925</td>
      <td>0.589776</td>
      <td>1.733132</td>
    </tr>
    <tr>
      <th>Tetanus</th>
      <td>25.304201</td>
      <td>-4.060205</td>
      <td>-29.364406</td>
      <td>-2.303780</td>
      <td>0.836177</td>
      <td>1.657389</td>
    </tr>
    <tr>
      <th>Hpylori</th>
      <td>25.432883</td>
      <td>-3.540561</td>
      <td>-28.973443</td>
      <td>-2.332328</td>
      <td>0.678948</td>
      <td>1.528708</td>
    </tr>
    <tr>
      <th>CMV</th>
      <td>25.585036</td>
      <td>-2.854813</td>
      <td>-28.439849</td>
      <td>-2.448170</td>
      <td>0.410953</td>
      <td>1.376554</td>
    </tr>
    <tr>
      <th>Listeria</th>
      <td>25.625607</td>
      <td>-3.472927</td>
      <td>-29.098534</td>
      <td>-2.302643</td>
      <td>0.515909</td>
      <td>1.335983</td>
    </tr>
    <tr>
      <th>Chagas</th>
      <td>25.629811</td>
      <td>-2.977678</td>
      <td>-28.607489</td>
      <td>-2.562489</td>
      <td>0.251859</td>
      <td>1.331780</td>
    </tr>
    <tr>
      <th>Vaccinia</th>
      <td>25.652124</td>
      <td>-3.102833</td>
      <td>-28.754957</td>
      <td>-1.920291</td>
      <td>0.871744</td>
      <td>1.309467</td>
    </tr>
    <tr>
      <th>StrepA</th>
      <td>25.652853</td>
      <td>-3.392241</td>
      <td>-29.045095</td>
      <td>-2.317461</td>
      <td>0.473844</td>
      <td>1.308737</td>
    </tr>
    <tr>
      <th>Meningococcus</th>
      <td>25.660310</td>
      <td>-3.107576</td>
      <td>-28.767886</td>
      <td>-2.360645</td>
      <td>0.423204</td>
      <td>1.301280</td>
    </tr>
    <tr>
      <th>Yeast</th>
      <td>25.817752</td>
      <td>-2.869042</td>
      <td>-28.686794</td>
      <td>-2.302663</td>
      <td>0.323743</td>
      <td>1.143839</td>
    </tr>
    <tr>
      <th>Ecoli</th>
      <td>25.818570</td>
      <td>-2.805620</td>
      <td>-28.624189</td>
      <td>-2.277082</td>
      <td>0.348507</td>
      <td>1.143021</td>
    </tr>
    <tr>
      <th>Human</th>
      <td>25.853997</td>
      <td>-2.590162</td>
      <td>-28.444159</td>
      <td>-2.590162</td>
      <td>0.000000</td>
      <td>1.107594</td>
    </tr>
    <tr>
      <th>Cattle</th>
      <td>25.876814</td>
      <td>-2.585898</td>
      <td>-28.462712</td>
      <td>-2.543528</td>
      <td>0.023816</td>
      <td>1.084776</td>
    </tr>
    <tr>
      <th>Mouse</th>
      <td>25.881926</td>
      <td>-2.542792</td>
      <td>-28.424718</td>
      <td>-2.537264</td>
      <td>0.024969</td>
      <td>1.079664</td>
    </tr>
    <tr>
      <th>Chicken</th>
      <td>25.920531</td>
      <td>-2.475510</td>
      <td>-28.396040</td>
      <td>-2.480620</td>
      <td>0.043008</td>
      <td>1.041060</td>
    </tr>
    <tr>
      <th>Soybean</th>
      <td>25.975130</td>
      <td>-2.451571</td>
      <td>-28.426700</td>
      <td>-2.309486</td>
      <td>0.159543</td>
      <td>0.986461</td>
    </tr>
    <tr>
      <th>Cockroach</th>
      <td>26.038071</td>
      <td>-2.297132</td>
      <td>-28.335203</td>
      <td>-2.281876</td>
      <td>0.124212</td>
      <td>0.923519</td>
    </tr>
  </tbody>
</table>
</div>




```python
plt.hist(df['DKL'])
```




    (array([14.,  8.,  0.,  3.,  4.,  0.,  0.,  0.,  0.,  1.]),
     array([0.        , 0.57413309, 1.14826618, 1.72239927, 2.29653235,
            2.87066544, 3.44479853, 4.01893162, 4.59306471, 5.1671978 ,
            5.74133089]),
     <a list of 10 Patch objects>)




![png](notebook_files/entropy_analysis_8_1.png)



```python
names = ['Human', 'Mouse', 'Vaccinia', 'InfluenzaB', 'InfluenzaA', 'CMV', 'HCV', 'HSV1',
       'DENV', 'HIV', 'EBV', 'Ebola', 'Ecoli', 'Tuberculosis', 'Listeria',
       'Burkholderia', 'Meningococcus', 'StrepA', 'Hpylori',
       'Lyme', 'Tetanus', 'Leprosy', 'Malaria', 'Chagas']

colors = matplotlib.rcParams['axes.prop_cycle'].by_key()['color']
type_to_color = {'virus' : colors[0],
                 'bacterium' : colors[1],
                 'parasite' : colors[2],
                 'vertebrate' : colors[3],
                 'uniform' : colors[4]
                }
proteomes = load_proteomes()
typecolors = [type_to_color[proteomes.loc[name]['type']] for name in names]
```


```python
df.loc[names].shape, typecolors
```




    (24, 6)




```python
lim = 4.0
ys = df.loc[names]['DKL_rand']
xs = df.loc[names]['DKL']
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(xs, ys, color=typecolors)
ax.plot([0, lim], [0, lim], 'k-')
ax.set_xlabel('$D_{KL}$(proteome $\parallel$ human)')
ax.set_ylabel('$D_{KL}$(proteome $\parallel$ uniform)')
ax.set_aspect('equal')
ax.set_xlim(-0.0, lim)
ax.set_ylim(-0.0, lim)
for i, (type_, color) in enumerate(type_to_color.items()):
    ax.text(0.8, 0.2-i*0.03, type_, color=color, transform=ax.transAxes)
fig.tight_layout()
```


![png](notebook_files/entropy_analysis_11_0.png)



```python

```
#### densityofstates.ipynb

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *
```


```python
params = np.load('data/Human_reference_9.npz')
hi = params['hi']
Jij = params['Jij']
```


```python
datasets = ['train', 'test', 'model']
sample_matrices = {}
for dataset in datasets:
    sample_matrices[dataset] = load_matrix('data/%s_matrix.csv.gz' % dataset)
```


```python
observables = ['fi', 'fij', 'cij', 'fijk', 'cijk', 'fold_ijk']#, 'fijkl']
observables_dict = {key: dict() for key in observables}
for dataset in ['train', 'test', 'model']:
    params = np.load('data/%s_observables.npz'%dataset)
    for observable in observables:
        observables_dict[observable][dataset] = params[observable]
```


```python
fi = observables_dict['fi']['train'].mean(axis=0)
sample_independent = np.random.choice(np.arange(0, 20, 1), size=sample_matrices['test'].shape, p=fi)
```


```python
arr = np.load('../aafreqpca/data/data.npz')
aa_human = arr['human']
```


```python
cov = np.cov(aa_human.T)
alpha = np.mean(aa_human, axis=0)
alpha0 = alpha*(1-alpha)/np.diag(cov) - 1.0
alpha0
```




    array([103.97144572,  52.27539978, 173.05226162,  84.67300122,
           140.7069723 ,  92.61090593, 172.27398996, 116.7177847 ,
            78.21749722, 112.76767947, 235.91539032, 169.00405327,
            67.41864509, 145.6206498 , 118.92310653, 114.44634793,
           191.08027332, 178.04419657, 198.44854756, 169.26510308])




```python
p = np.random.dirichlet(alpha*np.mean(alpha0), size=aa_human.shape[0])
bins = np.arange(0, 0.25, 0.01)
plt.hist(p[:, 5], bins=bins, histtype='step')
plt.hist(aa_human[:, 5], bins=bins, histtype='step')
```




    (array([  16.,  107.,  521., 1521., 2914., 3777., 3639., 3001., 1962.,
            1148.,  665.,  320.,  186.,   85.,   63.,   52.,   19.,   14.,
              21.,   10.,    5.,    7.,    5.,    6.]),
     array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,
            0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,
            0.22, 0.23, 0.24]),
     <a list of 1 Patch objects>)




![png](notebook_files/densityofstates_7_1.png)



```python
sampless = []
ps = np.random.dirichlet(alpha*np.mean(alpha0), size=aa_human.shape[0]//2)
blocklength = sample_matrices['test'].shape[0]//len(ps)
for p in ps:
    samples = np.random.choice(np.arange(0, 20, 1),
                               size=(blocklength, sample_matrices['test'].shape[1]),
                               p=p)
    sampless.append(samples)
sample_dirichlet = np.concatenate(sampless)
```


```python
sampless = []
ps = aa_human
blocklength = sample_matrices['test'].shape[0]//len(ps)
for p in ps:
    samples = np.random.choice(np.arange(0, 20, 1),
                               size=(blocklength, sample_matrices['test'].shape[1]),
                               p=p)
    sampless.append(samples)
sample_composition = np.concatenate(sampless)
```


```python
energies = {}
for dataset in ['test', 'model']:
    energies[dataset] = np.array([energy_potts(x, hi, Jij) for x in sample_matrices[dataset]])
energies['independent'] = np.array([energy_potts(x, hi, Jij) for x in sample_independent])
energies['dirichlet'] = np.array([energy_potts(x, hi, Jij) for x in sample_dirichlet])
```


```python
energies['composition'] = np.array([energy_potts(x, hi, Jij) for x in sample_composition])
```


```python
sample_cov =  load_matrix('../globalmaxent/data/model_matrix.csv.gz')
energies['cov'] = np.array([energy_potts(x, hi, Jij) for x in sample_cov])
```


```python
sample_third =  load_matrix('../globalmaxent/data/model_third_matrix.csv.gz')
energies['third'] = np.array([energy_potts(x, hi, Jij) for x in sample_third])
```


```python
bins = np.linspace(-6, 16, 100)
fig, ax = plt.subplots()
for dataset in ['test', 'independent', 'model', 'cov', 'third']:
    ax.hist(-energies[dataset], bins=bins, histtype='step', label=dataset)
ax.set_yscale('log')
ax.legend()
ax.set_xlabel('-Energy')
ax.set_ylabel('Density')
fig.tight_layout()
fig.savefig('density_of_states.png')
```


![png](notebook_files/densityofstates_14_0.png)



```python
bins = np.linspace(-6, 16, 300)
fig, ax = plt.subplots()
for dataset in ['test', 'independent', 'model', 'cov', 'third']:
    ax.hist(-energies[dataset], bins=bins, histtype='step', label=dataset)
ax.legend()
ax.set_xlabel('-Energy')
ax.set_ylabel('Density')
fig.tight_layout()
```


![png](notebook_files/densityofstates_15_0.png)



```python

```
#### entropy_calculation.ipynb

```python
import itertools, json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from matplotlib import colors

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *
```


```python
output = True
N = 9
q = naminoacids

proteome = proteome_path('Human')
seed = 1234
prng = np.random.RandomState(seed)
```


```python
params = np.load('data/Human_full_k9.npz')
hi = params['hi']
Jij = params['Jij']
```


```python
datasets = ['train', 'test', 'model']
sample_matrices = {}
for dataset in datasets:
    sample_matrices[dataset] =  np.loadtxt('data/%s_matrix.csv.gz' % dataset).astype(int)
```


```python
energies = [energy_potts(x, hi, Jij) for x in sample_matrices['model']]
```


```python
F0 = -np.sum(np.log(np.sum(np.exp(hi), axis=1)))
```


```python
def Fprime(alpha):
    jump = lambda x: local_jump(x, q)
    x0 = prng.randint(q, size=N)
    matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, alpha*Jij), jump, 1e6, nsample=10, nburnin=1e3)
    return np.mean([energy_potts(x, np.zeros_like(hi), Jij) for x in matrix])
```


```python
xs = np.linspace(0, 1, 4)
Fprimes = [Fprime(x) for x in xs]
```


```python
Fint = scipy.integrate.simps(Fprimes, xs)
Fint
```




    0.10532807605400357




```python
F0, np.mean(energies), Fint
```




    (-28.01652616764632, -2.072497153551555, 0.10532807605400357)




```python
energies_ind = [energy_potts(x, hi, np.zeros_like(Jij)) for x in independent_matrix]
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-34-b91115b0635f> in <module>
    ----> 1 energies_ind = [energy_potts(x, hi, np.zeros_like(Jij)) for x in independent_matrix]
    

    NameError: name 'independent_matrix' is not defined



```python
np.mean(energies_ind), np.mean(energies)
```


```python
def calc_Sind(hi):
    fis = np.exp(hi)/np.sum(np.exp(hi), axis=1)[:, np.newaxis]
    return np.sum(scipy.stats.entropy(fis.T))
```


```python
Sind = calc_Sind(hi)
S = np.mean(energies) - (F0 + Fint)
S, Sind
```


```python
Sind, np.mean(energies_ind) - F0
```


```python
Suni = np.log2(20)
```


```python
Sind*np.log2(np.exp(1))/N, S*np.log2(np.exp(1))/N
```


```python
df = pd.read_csv('../kmerentropy/data/entropy.csv')
```


```python
np.array(df['Human'])/np.arange(1, 6)
```




    array([4.17756346, 4.16934288, 4.16129658, 4.14931991, 4.11369582])




```python
(Sind-S)*np.log2(np.exp(1))
```




    0.30957087318646137




```python
def entropy_thermodynamic_integration(hi, Jij, integration_intervals=1, mcmc_kwargs=dict()):
    F0 = -np.sum(np.log(np.sum(np.exp(hi), axis=1)))
    N, q = hi.shape
    
    jump = lambda x: local_jump(x, q)
    x0 = prng.randint(q, size=N)
    matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, Jij), jump, **mcmc_kwargs)
    energy_mean = np.mean([energy_potts(x, hi, Jij) for x in matrix])
    
    def Fprime(alpha):
        jump = lambda x: local_jump(x, q)
        x0 = prng.randint(q, size=N)
        matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, alpha*Jij), jump, **mcmc_kwargs)
        return np.mean([energy_potts(x, np.zeros_like(hi), Jij) for x in matrix])
    
    xs = np.linspace(0, 1, integration_intervals+1)
    Fprimes = [Fprime(x) for x in xs]
    Fint = scipy.integrate.simps(Fprimes, xs)
    
    S = energy_mean - (F0 + Fint)
    return S
```


```python
mcmc_kwargs = dict(nsteps=1e6, nsample=10, nburnin=1e3)
```


```python
entropy_thermodynamic_integration(hi, Jij, integration_intervals=3, mcmc_kwargs=mcmc_kwargs)
```




    25.828290270215764




```python

```
#### distribution_hamming_distances.ipynb

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib

from numba import jit

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

```


```python
datasets = ['train', 'test', 'model']
sample_matrices = {}
for dataset in datasets:
    sample_matrices[dataset] =  load_matrix('data/%s_matrix.csv.gz' % dataset)[::9, :]
```


```python
sample_matrices['cov'] = load_matrix('../globalmaxent/data/model_matrix.csv.gz')[::9, :]
```


```python
observables = ['fi', 'fij', 'cij', 'fijk', 'cijk', 'fold_ijk']#, 'fijkl']
observables_dict = {key: dict() for key in observables}
for dataset in ['train']:
    params = np.load('data/%s_observables.npz'%dataset)
    for observable in observables:
        observables_dict[observable][dataset] = params[observable]
```


```python
fi = observables_dict['fi']['train'].mean(axis=0)
sample_matrices['independent'] = np.random.choice(np.arange(0, 20, 1), size=sample_matrices['test'].shape, p=fi)
```


```python
sample_matrices['flat'] = np.random.choice(np.arange(0, 20, 1), size=sample_matrices['test'].shape)
```


```python
nsample = 8e7
L = sample_matrices['test'].shape[1]
hists_dict = {}
for dataset in ['test', 'model', 'independent', 'flat', 'cov']:
    hists_dict[dataset] = pairwise_distances_jit(sample_matrices[dataset], N=nsample)
```


```python
bins = np.arange(L+1)
fig, ax = plt.subplots()
for dataset in ['flat', 'independent', 'model', 'test', 'cov']:
    ax.step(bins, hists_dict[dataset], label=dataset, where='mid')
ax.set_yscale('log')
ax.set_xticks(bins)
ax.set_xlim(bins[0], bins[-1])
ax.legend(loc='upper left');
```


![png](notebook_files/distribution_hamming_distances_7_0.png)



```python
filtered = kmers_to_matrix(to_kmers(pd.read_csv('../pfam/data/human_downsampled.csv')['Sequence'], 9))[::9]
```


```python
hists_dict['filtered'] = pairwise_distances_jit(filtered, N=nsample)
```


```python
hists_dict['train_test'] = pairwise_distances_jit(sample_matrices['train'],
                                                  data2=sample_matrices['test'],
                                                  N=nsample)
```


```python
arr = np.load('../aafreqpca/data/data.npz')
aa_human = arr['human']
ps = aa_human
blocklength = sample_matrices['test'].shape[0]//len(ps)
sampless = []
for p in ps:
    samples = np.random.choice(np.arange(0, 20, 1),
                               size=(blocklength, sample_matrices['test'].shape[1]),
                               p=p)
    sampless.append(samples)
sample_composition = np.concatenate(sampless)
```


```python
hists_dict['composition'] = pairwise_distances_jit(sample_composition, N=nsample)
```


```python
fig, ax = plt.subplots()
for dataset in ['flat', 'independent', 'model', 'train_test', 'cov', 'filtered']:
    ax.errorbar(bins, (hists_dict[dataset])/(hists_dict['test']),
                hists_dict[dataset]**.5/hists_dict['test'],
                label=dataset)
ax.set_xticks(bins)
ax.axhline(1.0, c='k')
ax.set_ylim(0.0, 1.1)
ax.legend(loc='lower right')
ax.set_xlabel('Hamming distance')
ax.set_ylabel('Relative to data');
```


![png](notebook_files/distribution_hamming_distances_13_0.png)



```python
pairwise_hist = {}
for dataset in ['model', 'independent', 'flat', 'cov']:
    pairwise_hist[dataset] = pairwise_distances_jit(sample_matrices[dataset],
                                   data2=sample_matrices['test'],
                                   N=nsample)
```


```python
fig, ax = plt.subplots()
ax.step(bins, hists_dict['test'], where='mid', label='data|data')
for dataset in ['flat', 'independent', 'model', 'cov']:
    ax.step(bins, pairwise_hist[dataset], where='mid', label=dataset + '|data')
ax.set_yscale('log')
ax.set_xticks(bins);
ax.legend(loc='upper left')
ax.set_xlabel('Hamming distance')
ax.set_ylabel('Count');
```


![png](notebook_files/distribution_hamming_distances_15_0.png)



```python
fig, ax = plt.subplots()
for dataset in ['flat', 'independent', 'model', 'cov']:
    ax.errorbar(bins, pairwise_hist[dataset]/hists_dict['test'],
                pairwise_hist[dataset]**.5/hists_dict['test'],
                label=dataset)
ax.set_xticks(bins)
ax.legend(loc='lower right')
ax.axhline(1.0, c='k')
ax.set_xlabel('Hamming distance')
ax.set_ylabel('Relative to data');
```


![png](notebook_files/distribution_hamming_distances_16_0.png)



```python

```
#### cijk_inspection.ipynb

```python
import itertools, json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from matplotlib import colors

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *
import xarray as xr
```


```python
observables = ['fi', 'fij', 'cij', 'fijk', 'cijk', 'fold_ijk']#, 'fijkl']
observables_dict = {key: dict() for key in observables}
for dataset in ['train', 'test', 'model']:
    params = np.load('data/%s_observables.npz'%dataset)
    for observable in observables:
        observables_dict[observable][dataset] = params[observable]
```


```python
L = observables_dict['fi']['test'].shape[0]
```


```python
#for i in range(L):
#    for j in range(L):
#        for k in range(L):
#            if (i == j) or (j == k) or (i==k):
#                observables_dict['cijk']['test'][i,j,k] = 0.0
for i in range(L):
    for j in range(L):
        for k in range(L):
            if not ((i < j) and (j < k)):
                observables_dict['cijk']['test'][i,j,k] = 0.0
```


```python
cijk_xr = xr.DataArray(observables_dict['cijk']['test'],
             dims=("i", "j", 'k', 'alpha', 'beta', 'gamma'),
             coords={'i': range(L),
                     'j': range(L),
                     'k': range(L),
                     'alpha': list(aminoacids),
                     'beta':list(aminoacids),
                     'gamma':list(aminoacids)})
```


```python
cijk_df = cijk_xr.to_dataframe('cijk')
```


```python
cijk_df_flat = cijk_df.loc[0].reset_index()
```


```python
cijk_df_flat.sort_values('cijk').tail(n=30)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>j</th>
      <th>k</th>
      <th>alpha</th>
      <th>beta</th>
      <th>gamma</th>
      <th>cijk</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>97263</th>
      <td>1</td>
      <td>3</td>
      <td>E</td>
      <td>E</td>
      <td>E</td>
      <td>0.000359</td>
    </tr>
    <tr>
      <th>210501</th>
      <td>2</td>
      <td>8</td>
      <td>H</td>
      <td>G</td>
      <td>C</td>
      <td>0.000361</td>
    </tr>
    <tr>
      <th>268821</th>
      <td>3</td>
      <td>6</td>
      <td>P</td>
      <td>C</td>
      <td>C</td>
      <td>0.000362</td>
    </tr>
    <tr>
      <th>178105</th>
      <td>2</td>
      <td>4</td>
      <td>G</td>
      <td>G</td>
      <td>G</td>
      <td>0.000363</td>
    </tr>
    <tr>
      <th>191621</th>
      <td>2</td>
      <td>5</td>
      <td>Y</td>
      <td>C</td>
      <td>C</td>
      <td>0.000364</td>
    </tr>
    <tr>
      <th>416564</th>
      <td>5</td>
      <td>7</td>
      <td>C</td>
      <td>K</td>
      <td>F</td>
      <td>0.000371</td>
    </tr>
    <tr>
      <th>410245</th>
      <td>5</td>
      <td>6</td>
      <td>G</td>
      <td>P</td>
      <td>G</td>
      <td>0.000373</td>
    </tr>
    <tr>
      <th>169263</th>
      <td>2</td>
      <td>3</td>
      <td>E</td>
      <td>E</td>
      <td>E</td>
      <td>0.000375</td>
    </tr>
    <tr>
      <th>108905</th>
      <td>1</td>
      <td>4</td>
      <td>P</td>
      <td>G</td>
      <td>G</td>
      <td>0.000375</td>
    </tr>
    <tr>
      <th>176564</th>
      <td>2</td>
      <td>4</td>
      <td>C</td>
      <td>K</td>
      <td>F</td>
      <td>0.000378</td>
    </tr>
    <tr>
      <th>275726</th>
      <td>3</td>
      <td>7</td>
      <td>L</td>
      <td>H</td>
      <td>H</td>
      <td>0.000382</td>
    </tr>
    <tr>
      <th>253052</th>
      <td>3</td>
      <td>4</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000389</td>
    </tr>
    <tr>
      <th>501052</th>
      <td>6</td>
      <td>8</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000392</td>
    </tr>
    <tr>
      <th>88000</th>
      <td>1</td>
      <td>2</td>
      <td>A</td>
      <td>A</td>
      <td>A</td>
      <td>0.000403</td>
    </tr>
    <tr>
      <th>256428</th>
      <td>3</td>
      <td>5</td>
      <td>C</td>
      <td>C</td>
      <td>K</td>
      <td>0.000407</td>
    </tr>
    <tr>
      <th>89263</th>
      <td>1</td>
      <td>2</td>
      <td>E</td>
      <td>E</td>
      <td>E</td>
      <td>0.000412</td>
    </tr>
    <tr>
      <th>261052</th>
      <td>3</td>
      <td>5</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000416</td>
    </tr>
    <tr>
      <th>109052</th>
      <td>1</td>
      <td>4</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000419</td>
    </tr>
    <tr>
      <th>213052</th>
      <td>2</td>
      <td>8</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000425</td>
    </tr>
    <tr>
      <th>189052</th>
      <td>2</td>
      <td>5</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000426</td>
    </tr>
    <tr>
      <th>248425</th>
      <td>3</td>
      <td>4</td>
      <td>C</td>
      <td>C</td>
      <td>G</td>
      <td>0.000430</td>
    </tr>
    <tr>
      <th>341052</th>
      <td>4</td>
      <td>6</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000438</td>
    </tr>
    <tr>
      <th>173052</th>
      <td>2</td>
      <td>3</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000455</td>
    </tr>
    <tr>
      <th>197052</th>
      <td>2</td>
      <td>6</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000458</td>
    </tr>
    <tr>
      <th>101052</th>
      <td>1</td>
      <td>3</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000465</td>
    </tr>
    <tr>
      <th>269052</th>
      <td>3</td>
      <td>6</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000475</td>
    </tr>
    <tr>
      <th>181052</th>
      <td>2</td>
      <td>4</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000486</td>
    </tr>
    <tr>
      <th>93052</th>
      <td>1</td>
      <td>2</td>
      <td>P</td>
      <td>P</td>
      <td>P</td>
      <td>0.000486</td>
    </tr>
    <tr>
      <th>272424</th>
      <td>3</td>
      <td>7</td>
      <td>C</td>
      <td>C</td>
      <td>F</td>
      <td>0.000510</td>
    </tr>
    <tr>
      <th>266105</th>
      <td>3</td>
      <td>6</td>
      <td>G</td>
      <td>G</td>
      <td>G</td>
      <td>0.001160</td>
    </tr>
  </tbody>
</table>
</div>




```python

```
#### maxent_analysis.ipynb

```python
import itertools, json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from matplotlib import colors

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

import evcouplings.align, evcouplings.couplings
```


```python
output = True
N = 9
q = naminoacids

proteome = proteome_path('Human')
seed = 1234
prng = np.random.RandomState(seed)
```


```python
params = np.load('data/Human_full_k9.npz')
hi = params['hi']
Jij = params['Jij']
```


```python
datasets = ['train', 'test', 'model']
sample_matrices = {}
for dataset in datasets:
    sample_matrices[dataset] =  np.loadtxt('data/%s_matrix.csv.gz' % dataset).astype(int)
```


    ---------------------------------------------------------------------------

    KeyboardInterrupt                         Traceback (most recent call last)

    <ipython-input-61-498c1022ff5e> in <module>
          2 sample_matrices = {}
          3 for dataset in datasets:
    ----> 4     sample_matrices[dataset] =  np.loadtxt('data/%s_matrix.csv.gz' % dataset).astype(int)
    

    ~/.conda/envs/py3/lib/python3.6/site-packages/numpy/lib/npyio.py in loadtxt(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)
       1157         # converting the data
       1158         X = None
    -> 1159         for x in read_data(_loadtxt_chunksize):
       1160             if X is None:
       1161                 X = np.array(x, dtype)


    ~/.conda/envs/py3/lib/python3.6/site-packages/numpy/lib/npyio.py in read_data(chunk_size)
       1085 
       1086             # Convert each value according to its column and store
    -> 1087             items = [conv(val) for (conv, val) in zip(converters, vals)]
       1088 
       1089             # Then pack it according to the dtype's nesting


    KeyboardInterrupt: 



```python
for dataset in datasets:
    print(dataset, sample_matrices[dataset].shape)
```

    train (5702936, 9)
    test (5646474, 9)
    model (5646474, 9)



```python
fis = {}
fijs = {}
cijs = {}
for dataset in datasets:
    matrix = sample_matrices[dataset]
    fi = frequencies(matrix, num_symbols=q, pseudocount=0.0)
    fis[dataset] = fi
    fij = pair_frequencies(matrix, num_symbols=q, fi=fi, pseudocount=0.0)
    fijs[dataset] = fij
    cij = compute_covariance_matrix(fi=fi, fij=fij)
    cijs[dataset] = cij
```


```python
fijks = {}
for dataset in datasets:
    matrix = sample_matrices[dataset]
    fijk = triplet_frequencies(matrix, num_symbols=q, pseudocount=0.0)
    fijks[dataset] = fijk
```


```python
cijks = {}
for dataset in datasets:
    matrix = sample_matrices[dataset]
    fij = fijs[dataset]
    fi = fis[dataset]
    fijk = fijks[dataset]
    cijk = compute_cijk(fijk, fij, fi)
    cijks[dataset] = cijk
```


```python
plt.plot(flatten_ijk(cijks['test']), flatten_ijk(cijks['train']), 'o', ms=1)
```




    [<matplotlib.lines.Line2D at 0x7fd0b134d588>]




![png](notebook_files/maxent_analysis_8_1.png)



```python
fig, axes = plt.subplots(figsize=(7, 3.5), ncols=2)
for i, dataset in enumerate(['train', 'model']):
    plotting.density_scatter(flatten_ijk(cijks['test']),
                             flatten_ijk(cijks[dataset]),
                             trans=lambda x: np.log(x+1e-3),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i])
    axes[i].set_ylabel(dataset)
for ax in axes:
    max_ = 1.1*flatten_ijk(cijks['test']).max()
    lims = 1/max_, max_
    ax.plot(lims, lims, 'k-')
    ax.set_xscale('log')
    ax.set_yscale('log')
    ax.set_xlabel('test')
    ax.set_xlim(*lims)
    ax.set_ylim(*lims)
fig.tight_layout()
```


![png](notebook_files/maxent_analysis_9_0.png)



```python
jump = lambda x: local_jump(x, q)
x0 = prng.randint(q, size=N)
independent_matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, np.zeros_like(Jij)), jump, 1e7, nsample=10)
```


```python
fi_independent = frequencies(independent_matrix, num_symbols=q, pseudocount=0.0)
fij_independent = pair_frequencies(independent_matrix, num_symbols=q, fi=fi_independent, pseudocount=0.0)
fijk_independent = triplet_frequencies(independent_matrix, num_symbols=q, pseudocount=0.0)
```


```python
cijk_independent = compute_cijk(fijk_independent, fij_independent, fi_independent)
```


```python
plt.plot(flatten_ijk(cijks['test']), flatten_ijk(cijk_independent), 'o', ms=1)
```




    [<matplotlib.lines.Line2D at 0x7fd0b18072b0>]




![png](notebook_files/maxent_analysis_13_1.png)



```python
foldijks = {}
for dataset in datasets:
    fijk = fijks[dataset]
    fi = fis[dataset]
    fold_ijk = fijk / (fi[:, np.newaxis, np.newaxis, :, np.newaxis, np.newaxis] *
                fi[np.newaxis, :, np.newaxis, np.newaxis, :, np.newaxis] *
                fi[np.newaxis, np.newaxis :, np.newaxis, np.newaxis, :])
    foldijks[dataset] = fold_ijk
```


```python
params = np.load('data/Human_full_k9.npz')
hi = params['hi']
Jij = params['Jij']
```


```python
list(zip(aminoacids, hi.std(axis=0)))
```




    [('A', 0.0035406579075383795),
     ('C', 0.0014893643088148595),
     ('D', 0.0013892198615577393),
     ('E', 0.0009110189563667492),
     ('F', 0.0013412697278855862),
     ('G', 0.0014000822211791095),
     ('H', 0.002127311629294183),
     ('I', 0.0020652620217782598),
     ('K', 0.0026846894372483626),
     ('L', 0.0011654184849189324),
     ('M', 0.026951582205213515),
     ('N', 0.0012834177758636997),
     ('P', 0.0009682044299691245),
     ('Q', 0.0013840474784771529),
     ('R', 0.001142693073953028),
     ('S', 0.0009424551613649941),
     ('T', 0.0011721207550945312),
     ('V', 0.0008010794265122387),
     ('W', 0.0014400674267044922),
     ('Y', 0.0022629432493179095)]




```python
observables = ['fi', 'fij', 'cij', 'fijk', 'cijk', 'fold_ijk']#, 'fijkl']
observables_dict = {key: dict() for key in observables}
for dataset in ['train', 'test', 'model', 'model_global']:
    params = np.load('data/%s_observables.npz'%dataset)
    for observable in observables:
        observables_dict[observable][dataset] = params[observable]
```


```python
kmers = np.array([list(kmer) for kmer in
                  to_kmers(pd.read_csv('../pfam/data/human_nozf.csv')['Sequence'], 9)])
filtered = map_matrix(kmers, map_)[::9]
```


```python
matrix = filtered
fi = frequencies(matrix, num_symbols=naminoacids)
fij = pair_frequencies(matrix, num_symbols=naminoacids, fi=fi)
cij = compute_covariance_matrix(fi, fij)
fijk = triplet_frequencies(matrix, num_symbols=naminoacids)
cijk = compute_cijk(fijk, fij, fi)
```


```python
observables_dict['fi']['filtered'] = fi
observables_dict['cij']['filtered'] = cij
observables_dict['cijk']['filtered'] = cijk
```


```python
fig, ax = plt.subplots()
plotting.density_scatter(flatten_ijk(observables_dict['cijk']['test']),
                         flatten_ijk(cijk),
                         norm=colors.LogNorm(vmin=1),
                         s=0.5, bins=50, ax=ax)
ax.set_xlim(-8e-4, 8e-4)
ax.set_ylim(-8e-4, 8e-4)
```




    (-0.0008, 0.0008)




![png](notebook_files/maxent_analysis_21_1.png)



```python
fig, axes = plt.subplots(figsize=(8, 5), ncols=3, nrows=2)

for j, (observable, label, lims, flattener) in enumerate([('fi', '$f_i$', (0, 0.12), np.ravel),
                                               ('cij', '$C_{ij}$', (-0.0035, 0.0035), flatten_ij),
                                               ('cijk', '$C_{ijk}$', (-8e-4, 8e-4), flatten_ijk)]):
    for i, dataset in enumerate(['model', 'train']):
        ax = axes[i, j]
        if observable in ['cij', 'cijk']:
            flatten = flatten_ij if observable == 'cij' else flatten_ijk
            plotting.density_scatter(flatten(observables_dict[observable]['filtered']),
                             flatten(observables_dict[observable][dataset]),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=40, ax=ax)
        else:
            ax.plot(flattener(observables_dict[observable]['filtered']),
                    flattener(observables_dict[observable][dataset]),
                    'o', ms=1)
        
        ax.set_xlabel('test %s'%label)
        ax.set_ylabel('%s %s'%(dataset, label))
        ax.plot(lims, lims, 'k')
        ax.set_xlim(*lims)
        ax.set_ylim(*lims)

for ax in axes[:, 1:].flatten():
    ax.ticklabel_format(style='sci', scilimits=(0,0))

fig.tight_layout()
```


![png](notebook_files/maxent_analysis_22_0.png)



```python
fig, axes = plt.subplots(figsize=(7, 3.5), ncols=2)
label = r'$\frac{P(\sigma_i, \sigma_j, \sigma_k)}{P(\sigma_i)P(\sigma_j)P(\sigma_k)}$'
for i, dataset in enumerate(['model', 'train']):
    plotting.density_scatter(flatten_ijk(observables_dict['fold_ijk']['test']),
                             flatten_ijk(observables_dict['fold_ijk'][dataset]),
                             trans=lambda x: np.log(x),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i])
    axes[i].set_ylabel('%s %s'%(dataset, label))
for ax in axes:
    ax.set_xlabel('test %s'%label)
    
    max_ = 1.1*flatten_ijk(observables_dict['fold_ijk']['test']).max()
    lims = 1/max_, max_
    ax.plot(lims, lims, 'k-')
    ax.set_xscale('log')
    ax.set_yscale('log')
    ax.set_xlim(*lims)
    ax.set_ylim(*lims)
fig.tight_layout()
fig.savefig('fold.png')
```


![png](notebook_files/maxent_analysis_23_0.png)



```python
fig, axes = plt.subplots(figsize=(7, 3.5), ncols=2)
for i, dataset in enumerate(['model', 'train']):
    indices = 0,4,8
    plotting.density_scatter(observables_dict['fold_ijk']['test'][indices].flatten(),
                             observables_dict['fold_ijk'][dataset][indices].flatten(),
                             trans=lambda x: np.log(x),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i])
    axes[i].set_ylabel(dataset)
for ax in axes:
    max_ = 1.1*observables_dict['fold_ijk']['test'][indices].flatten().max()
    lims = 1/max_, max_
    ax.plot(lims, lims, 'k-')
    ax.set_xscale('log')
    ax.set_yscale('log')
    ax.set_xlabel('test')
    ax.set_xlim(*lims)
    ax.set_ylim(*lims)
fig.tight_layout()
```


![png](notebook_files/maxent_analysis_24_0.png)



```python
fig, axes = plt.subplots(figsize=(7, 3.5), ncols=2)
for i, dataset in enumerate(['model', 'train']):
    if dataset == 'model':
        fi = observables_dict['fi']['train']
        fijk_ind = (fi[:, np.newaxis, np.newaxis, :, np.newaxis, np.newaxis] *
                 fi[np.newaxis, :, np.newaxis, np.newaxis, :, np.newaxis] *
                 fi[np.newaxis, np.newaxis :, np.newaxis, np.newaxis, :])
        test = observables_dict['fijk']['test'][3,4,5,:,:,:].flatten()
        data = fijk_ind[3,4,5,:,:,:].flatten()
        print('ind', calc_jsd(test, data))
        axes[i].plot(test, data, 'o', ms=1)
    test = observables_dict['fijk']['test'][3,4,5,:,:,:].flatten()
    data = observables_dict['fijk'][dataset][3,4,5,:,:,:].flatten()
    print(dataset, calc_jsd(test, data))
    axes[i].plot(test, data, 'o', ms=1)
    axes[i].set_ylabel(dataset)
for ax in axes:
    #max_ = 1.1*flatten_ijk(observables_dict['fijk']['test']).max()
    #lims = 1/max_, max_
    #ax.plot(lims, lims, 'k-')
    ax.set_xscale('log')
    ax.set_yscale('log')
    ax.set_xlabel('test')
    #ax.set_xlim(*lims)
    #ax.set_ylim(*lims)
fig.tight_layout()
```

    ind 0.0073301421024185645
    model 0.0015892616068755262
    train 0.0004770915667735209



![png](notebook_files/maxent_analysis_25_1.png)



```python
fig, axes = plt.subplots(figsize=(7.5, 3.5), ncols=2)
for i, dataset in enumerate(['model', 'train']):
    plotting.density_scatter(flatten_ijk(observables_dict['cijk']['test']),
                             flatten_ijk(observables_dict['cijk'][dataset]),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i])
    axes[i].set_ylabel(dataset + ' $C_{ijk}$')
for ax in axes:
    lim = 7e-4
    lims = -lim, lim
    ax.plot(lims, lims, 'k-')
    ax.set_xlim(*lims)
    ax.set_ylim(*lims)
    ax.set_xlabel('test $C_{ijk}$')
fig.tight_layout()
```


![png](notebook_files/maxent_analysis_26_0.png)



```python
fig, axes = plt.subplots(figsize=(7.5, 3.5), ncols=2)
for i, dataset in enumerate(['model', 'train']):
    indices = 3,4,5
    plotting.density_scatter(observables_dict['cijk']['test'][indices].flatten(),
                             observables_dict['cijk'][dataset][indices].flatten(),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i])
    axes[i].set_ylabel(dataset + ' $C_{ijk}$')
for ax in axes:
    lim = 5e-4
    lims = -lim, lim
    ax.plot(lims, lims, 'k-')
    ax.set_xlim(*lims)
    ax.set_ylim(*lims)
    ax.set_xlabel('test $C_{ijk}$')
fig.tight_layout()
```


![png](notebook_files/maxent_analysis_27_0.png)



```python

```
#### Jij_analysis.ipynb

```python
import itertools, json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from matplotlib import colors
import seaborn as sns

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *
import xarray as xr
```


```python
params = np.load('data/Human_reference_9.npz')
hi = params['hi']
Jij = params['Jij']
```


```python
def zero_sum_gauge(J_ij):
    J_ijc = J_ij.copy()
    for i in range(Jij.shape[0]):
        J_ijc[i, i] = 0.0
    J_ij_0 = (J_ijc
              - np.mean(J_ijc, axis=2)[:, :, np.newaxis, :]
              - np.mean(J_ijc, axis=3)[:, :, :, np.newaxis]
              + np.mean(J_ijc, axis=(2,3))[:, :, np.newaxis, np.newaxis])
    return J_ij_0
```


```python
Jij0 = zero_sum_gauge(Jij)
```


```python
mean_Jij = Jij0.mean(axis=(0,1))
```


```python
L = hi.shape[0]
Jij_xr = xr.DataArray(Jij0-mean_Jij,
             dims=("i", "j", 'alpha', 'beta'),
             coords={'i': range(L),
                     'j': range(L),
                     'alpha': list(aminoacids),
                     'beta':list(aminoacids)
                    })
Jij_df = Jij_xr.to_dataframe('Jij').loc[0,:].reset_index()
Jij_df.dropna(inplace=True)
Jij_df.sort_values('Jij').tail(n=10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>j</th>
      <th>alpha</th>
      <th>beta</th>
      <th>Jij</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>768</th>
      <td>1</td>
      <td>W</td>
      <td>K</td>
      <td>0.202598</td>
    </tr>
    <tr>
      <th>603</th>
      <td>1</td>
      <td>M</td>
      <td>E</td>
      <td>0.204113</td>
    </tr>
    <tr>
      <th>463</th>
      <td>1</td>
      <td>E</td>
      <td>E</td>
      <td>0.204857</td>
    </tr>
    <tr>
      <th>1305</th>
      <td>3</td>
      <td>G</td>
      <td>G</td>
      <td>0.207567</td>
    </tr>
    <tr>
      <th>645</th>
      <td>1</td>
      <td>P</td>
      <td>G</td>
      <td>0.207732</td>
    </tr>
    <tr>
      <th>471</th>
      <td>1</td>
      <td>E</td>
      <td>N</td>
      <td>0.230310</td>
    </tr>
    <tr>
      <th>1221</th>
      <td>3</td>
      <td>C</td>
      <td>C</td>
      <td>0.253613</td>
    </tr>
    <tr>
      <th>3161</th>
      <td>7</td>
      <td>W</td>
      <td>C</td>
      <td>0.269369</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>5</td>
      <td>C</td>
      <td>C</td>
      <td>0.287882</td>
    </tr>
    <tr>
      <th>600</th>
      <td>1</td>
      <td>M</td>
      <td>A</td>
      <td>0.316486</td>
    </tr>
  </tbody>
</table>
</div>




```python
fig, axes = plt.subplots(figsize=(3, 8), sharex=True, sharey=True, nrows=L)
for j in range(1, L):
    ax = axes[j-1]
    ax.hist(Jij_df[Jij_df['j']==j]['Jij'], bins=np.arange(-0.4, 1.0, 0.05), histtype='step')
    ax.text(0.95, 0.95, 'd = %i'%j, transform=ax.transAxes, va='top', ha='right')
ax = axes[-1]
ax.hist(mean_Jij.flatten(), bins=np.arange(-0.4, 1.0, 0.05), histtype='step')
ax.text(0.95, 0.95, 'mean', transform=ax.transAxes, va='top', ha='right')
for ax in axes:
    ax.set_yscale('log')
```


![png](notebook_files/Jij_analysis_6_0.png)



```python
for j in range(1, 9):
    plt.scatter(mean_Jij, Jij0[0, j], s=2)
```


![png](notebook_files/Jij_analysis_7_0.png)



```python
dist = np.arange(1, 9)
for i in range(naminoacids):
    plt.plot(dist, Jij0[0, dist][:,i,i]-np.mean(Jij0[0, dist][:,i,i]))
```


![png](notebook_files/Jij_analysis_8_0.png)



```python
symmetrized = np.zeros_like(mean_Jij)
for i in range(naminoacids):
    for j in range(naminoacids):
        symmetrized[i, j] = 0.5*(mean_Jij[i, j] + mean_Jij[j, i])
```


```python
def label(ax, aminoacidorder):
    ax.set_xticks(range(naminoacids))
    ax.set_yticks(range(naminoacids))
    ax.set_xticklabels(list(aminoacidorder))
    ax.set_yticklabels(list(aminoacidorder))
```


```python
aminoacids_coucke = 'ACFILMVWYPHKRDENQSTG'
```


```python
indices = [aminoacids.index(aa) for aa in aminoacids_coucke]
```


```python
imshow_kwargs = dict(vmin=-0.25, vmax=0.25, cmap='coolwarm')
fig, axes_arr = plt.subplots(figsize=(9, 9), nrows=3, ncols=3)
axes = axes_arr.flatten()
for j in range(1, 9):
    ax = axes[j-1]
    im = ax.imshow((Jij0[0,j]-mean_Jij)[indices, :][:, indices], **imshow_kwargs)
    ax.set_title(j)
    label(ax, aminoacids_coucke)
    fig.colorbar(im, ax=ax, shrink=0.7)
ax = axes[-1]
im = ax.imshow(mean_Jij[indices, :][:, indices], **imshow_kwargs)
ax.set_title('mean')
label(ax, aminoacids_coucke)
fig.colorbar(im, ax=ax, shrink=0.7)
fig.tight_layout()
```


![png](notebook_files/Jij_analysis_13_0.png)



```python
for j in range(1, L):
    sns.regplot(mean_Jij.flatten(), (Jij0[0,j]-mean_Jij).flatten(), label=j)
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f51f4df7e80>




![png](notebook_files/Jij_analysis_14_1.png)



```python
fig, axes_arr = plt.subplots(figsize=(9, 8), nrows=2, ncols=2)
axes = axes_arr.flatten()
U, s, Vh = scipy.linalg.svd(Jij0[0, 2]-mean_Jij)
for i in range(4):
    im = axes[i].imshow((s[i]*np.outer(U.T[i], Vh[i]))[indices, :][:, indices], **imshow_kwargs)
    axes[i].set_title(i+1)
    label(axes[i], aminoacids_coucke)
    fig.colorbar(im, ax=axes[i], shrink=0.7)
fig.tight_layout()
```


![png](notebook_files/Jij_analysis_15_0.png)



```python
w, v = scipy.linalg.eigh(symmetrized)
```


```python
plt.hist(w, bins=np.arange(-0.2, 0.9, 0.05))
```




    (array([0., 0., 1., 1., 3., 2., 4., 2., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
            0., 1., 1., 0.]),
     array([-2.00000000e-01, -1.50000000e-01, -1.00000000e-01, -5.00000000e-02,
            -5.55111512e-17,  5.00000000e-02,  1.00000000e-01,  1.50000000e-01,
             2.00000000e-01,  2.50000000e-01,  3.00000000e-01,  3.50000000e-01,
             4.00000000e-01,  4.50000000e-01,  5.00000000e-01,  5.50000000e-01,
             6.00000000e-01,  6.50000000e-01,  7.00000000e-01,  7.50000000e-01,
             8.00000000e-01,  8.50000000e-01]),
     <a list of 21 Patch objects>)




![png](notebook_files/Jij_analysis_17_1.png)



```python
arr = np.load('../aafreqpca/data/data.npz')
aa_human = arr['human']
```


```python
cov = np.cov(aa_human.T)
```


```python
fig, axes = plt.subplots(figsize=(9, 4), ncols=2)
for i, matrix in enumerate([cov, mean_Jij]):
    ax = axes[i]
    im = ax.imshow(matrix[indices, :][:, indices], vmin=-matrix.max(), vmax=matrix.max(), cmap='coolwarm')
    label(ax, aminoacids_coucke)
    fig.colorbar(im, ax=ax, shrink=0.7)
fig.tight_layout()
```


![png](notebook_files/Jij_analysis_20_0.png)



```python

```
#### meanfield.ipynb

```python
import itertools, json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from matplotlib import colors

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

import evcouplings.couplings
```


```python
params = np.load('data/Human_9.npz')
hi = params['hi']
Jij = params['Jij']
```


```python
L, q = hi.shape
L, q
```




    (9, 20)




```python
observables = ['fi', 'fij', 'cij', 'fijk', 'cijk', 'fold_ijk']#, 'fijkl']
observables_dict = {key: dict() for key in observables}
for dataset in ['train', 'test', 'model']:
    params = np.load('data/%s_observables.npz'%dataset)
    for observable in observables:
        observables_dict[observable][dataset] = params[observable]
```


```python
@numba.jit(nopython=True)
def _flatten_index(i, alpha, q):
    """
    Map position and symbol to index in
    the covariance matrix.
    Parameters
    ----------
    i : int, np.array of int
        The alignment column(s).
    alpha : int, np.array of int
        The symbol(s).
    q : int
        The number of symbols of the
        alphabet used.
    """
    return i * (q - 1) + alpha
```


```python
@numba.jit(nopython=True)
def reshape_invcov_to_4d(inv_cov_matrix, L, q):
    """
    "Un-flatten" flattened covariance matrix
    
    Parameters
    ----------
    inv_cov_matrix : np.array
        The matrix to be flattened
    L : int
        Model length.
    q : int
        Number of characters in the alphabet.
    Returns
    -------
    np.array
        Matrix of size L x L x
        q x q.
    """
    inv = np.zeros((L, L, q, q))
    for i in range(L):
        for j in range(L):
            for alpha in range(q - 1):
                for beta in range(q - 1):
                    inv[i, j, alpha, beta] = inv_cov_matrix[
                        _flatten_index(i, alpha, q),
                        _flatten_index(j, beta, q)
                    ]
    return inv
```


```python
def compute_Jij_mf(cij_flat):
    invC = np.linalg.inv(cij_flat)
    Jij = -reshape_invcov_to_4d(invC, L, q)
    return Jij
```


```python
@numba.jit(nopython=True)
def fields(J_ij, f_i):
    """
    Compute fields in q gauge.
    
    Parameters
    ----------
    J_ij : np.array
        Matrix of size L x L x q x q
        containing coupling parameters.
    f_i : np.array
        Matrix of size L x q
        containing single-site frequencies.
    Returns
    -------
    np.array
        Matrix of size L x q
        containing single-site fields.
    """
    L, q = f_i.shape
    hi = np.zeros((L, q))
    for i in range(L):
        log_fi = np.log(f_i[i] / f_i[i, q-1])
        J_ij_sum = np.zeros((1, q))
        for j in range(L):
            if i != j:
                # some eij values over beta from 1 to q-1
                J_ij_sum += np.dot(J_ij[i, j, :, :q-1], f_i[j, :q-1]).T
        hi[i] = log_fi - J_ij_sum
    return hi
```


```python
fi = observables_dict['fi']['train']
fij = observables_dict['fij']['train']
alpha = 1e-8
fi_reg = (1-alpha)*fi + alpha/q
fij_reg = (1-alpha)*fij + alpha/q**2
cij_flat = compute_flattened_covariance_matrix(fi_reg, fij_reg)
Jij_mf = compute_Jij_mf(cij_flat)
hi_mf = fields(Jij_mf, fi_reg)
```

    <ipython-input-8-c53c1d109231>:28: NumbaPerformanceWarning: [1m[1mnp.dot() is faster on contiguous arrays, called on (array(float64, 2d, A), array(float64, 1d, C))[0m[0m
      J_ij_sum += np.dot(J_ij[i, j, :, :q-1], f_i[j, :q-1]).T



```python
L, q = fi.shape
rhoij = np.zeros(fij.shape)
for i in range(L):
    for j in range(L):
        rhoij[i, j] = fij[i, j]/np.outer(fi[i], fi[j]) - 1.0
plt.plot(flatten_ij(rhoij), flatten_ij(zero_sum_gauge(Jij)),
         '.', ms=1, label='fitted')
plt.plot(flatten_ij(rhoij), flatten_ij(zero_sum_gauge(Jij_mf)),
         '.', ms=1, label='mf')
lim = 1.0
plt.plot([-lim, lim], [-lim, lim], 'k-')
plt.xlabel(r'$\rho_{ij}$')
plt.ylabel('$J_{ij}$')
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fac0de03d68>




![png](notebook_files/meanfield_9_1.png)



```python
bins = np.linspace(-1, 1, 20)
plt.hist(flatten_ij(zero_sum_gauge(Jij)), bins=bins, histtype='step')
plt.hist(flatten_ij(zero_sum_gauge(Jij_mf)), bins=bins, histtype='step');
```


![png](notebook_files/meanfield_10_0.png)



```python
Jij_mf_zero = zero_sum_gauge(Jij_mf)
hi_mf_zero = fields(Jij_mf_zero, fi)
```


```python
prng = np.random
jump = lambda x: local_jump(x, q)
x0 = prng.randint(q, size=L)
sample_matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi_mf, Jij_mf), jump, 1e6, nsample=10, nburnin=1e4)
```


```python
fi_mf = frequencies(sample_matrix, num_symbols=q)
fij_mf = pair_frequencies(sample_matrix, num_symbols=q, fi=fi_mf)
cij_mf = compute_covariance_matrix(fi_mf, fij_mf)
```


```python
fig, axes = plt.subplots(figsize=(7, 3.2), ncols=2)

ax = axes[0]
lims = [0, 0.12]
ax.plot(np.ravel(fi), np.ravel(fi_mf), 'o', ms=2)
ax.set_xlabel('training $f_i$')
ax.set_ylabel('mf $f_i$')
ax.plot(lims, lims, 'k')
ax.set_xlim(*lims)
ax.set_ylim(*lims)

ax = axes[1]
lims = [-0.3e-2, 1.5e-2]
plotting.density_scatter(flatten_ij(observables_dict['cij']['train']),
                         flatten_ij(cij_mf),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=30, ax=ax)
#ax.plot(flatten_ij(observables_dict['cij']['train']), flatten_ij(cij_mf), 'o', ms=1)
ax.set_ylabel('mean-field $C_{ij}$')
ax.set_xlabel('training $C_{ij}$')
ax.plot(lims, lims, 'k')
ax.set_xlim(*lims)
ax.set_ylim(*lims)
ax.ticklabel_format(style='sci', scilimits=(0,0))

fig.tight_layout()
fig.savefig('meanfield.png')
```

    /home/amayer/.conda/envs/py3/lib/python3.6/site-packages/matplotlib/colors.py:1110: RuntimeWarning: invalid value encountered in less_equal
      mask |= resdat <= 0



![png](notebook_files/meanfield_14_1.png)



```python
invC = np.linalg.inv(cij_flat)
invC4d = reshape_invcov_to_4d(invC, L, q)
Jij_TAP = -2*invC4d/(1+(1-8*invC4d*fi[:, np.newaxis, :, np.newaxis]*fi[np.newaxis, :, np.newaxis, :])**.5)
```

    /home/amayer/.conda/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in sqrt
      This is separate from the ipykernel package so we can avoid doing imports until



```python
flatten_ij(Jij_TAP).mean(), flatten_ij(Jij_mf).mean()
```




    (0.19261893913664105, 0.1930600243824052)




```python
plt.hist(flatten_ij(Jij_TAP));
```


![png](notebook_files/meanfield_17_0.png)



```python
plt.plot(flatten_ij(Jij_mf), flatten_ij(Jij_TAP), 'o')
plt.plot([-1, 3], [-1, 3])
```




    [<matplotlib.lines.Line2D at 0x7fac0e32e908>]




![png](notebook_files/meanfield_18_1.png)



```python
L, q = fi.shape
rhoij = np.zeros(fij.shape)
for i in range(L):
    for j in range(L):
        rhoij[i, j] = fij[i, j]/np.outer(fi[i], fi[j]) - 1.0
plt.plot(flatten_ij(rhoij), flatten_ij(zero_sum_gauge(Jij)),
         '.', ms=1, label='fitted')
plt.plot(flatten_ij(rhoij), flatten_ij(zero_sum_gauge(Jij_TAP)),
         '.', ms=1, label='mf')
lim = 1.0
plt.plot([-lim, lim], [-lim, lim], 'k-')
plt.xlabel(r'$\rho_{ij}$')
plt.ylabel('$J_{ij}$')
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fac0e443da0>




![png](notebook_files/meanfield_19_1.png)



```python
arr = np.load('../aafreqpca/data/data.npz')
aa_human = arr['human']
ps = aa_human
blocklength = int(1e7)//len(ps)
sampless = []
for p in ps:
    samples = np.random.choice(np.arange(0, 20, 1),
                               size=(blocklength, L),
                               p=p)
    sampless.append(samples)
sample_composition = np.concatenate(sampless)
```


```python
q = naminoacids
fi = frequencies(sample_composition, num_symbols=q)
fij = pair_frequencies(sample_composition, num_symbols=q, fi=fi)
cij = compute_covariance_matrix(fi, fij)
```


```python
cij_flat = compute_flattened_covariance_matrix(fi, fij)
Jij_comp = compute_Jij_mf(cij_flat)
Jij_comp = zero_sum_gauge(Jij_comp)
hi_comp = fields(Jij_comp, fi)
```


```python
plotting.density_scatter(flatten_ij(Jij), flatten_ij(Jij_comp), s=1)
x = np.linspace(-0.3, 0.7)
plt.plot(x,x)
```




    [<matplotlib.lines.Line2D at 0x7fac0e3ba1d0>]




![png](notebook_files/meanfield_23_1.png)



```python
x0 = prng.randint(q, size=L)
sample_matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi_comp, Jij_comp), jump, 5e6, nsample=10, nburnin=1e4)
```


```python
fi_mf = frequencies(sample_matrix, num_symbols=q)
fij_mf = pair_frequencies(sample_matrix, num_symbols=q, fi=fi_mf)
cij_mf = compute_covariance_matrix(fi_mf, fij_mf)
```


```python
cov = np.cov(aa_human.T)
plt.plot(flatten_ij(cij), flatten_ij(cij_mf), 'o', ms=1)
x = np.linspace(-2e-4, 1e-3)
plt.plot(x,x)
```




    [<matplotlib.lines.Line2D at 0x7fac111d6128>]




![png](notebook_files/meanfield_26_1.png)



```python
fig, axes = plt.subplots(figsize=(7, 3.2), ncols=2)

ax = axes[0]
lims = [0, 0.12]
ax.plot(np.ravel(fi), np.ravel(fi_mf), 'o', ms=2)
ax.set_xlabel('training $f_i$')
ax.set_ylabel('mf $f_i$')
ax.plot(lims, lims, 'k')
ax.set_xlim(*lims)
ax.set_ylim(*lims)

ax = axes[1]
lims = [-0.3e-2, 0.5e-2]
plotting.density_scatter(flatten_ij(observables_dict['cij']['train']),
                         flatten_ij(cij_mf),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=30, ax=ax)
ax.set_ylabel('mean-field $C_{ij}$')
ax.set_xlabel('training $C_{ij}$')
ax.plot(lims, lims, 'k')
ax.set_xlim(*lims)
ax.set_ylim(*lims)
ax.ticklabel_format(style='sci', scilimits=(0,0))

fig.tight_layout()
fig.savefig('meanfield.png')
```


![png](notebook_files/meanfield_27_0.png)



```python
fig, axes = plt.subplots(figsize=(7, 3.2), ncols=2)

ax = axes[0]
lims = [0, 0.12]
ax.plot(np.ravel(fi), np.ravel(fi), 'o', ms=2)
ax.set_xlabel('training $f_i$')
ax.set_ylabel('mf $f_i$')
ax.plot(lims, lims, 'k')
ax.set_xlim(*lims)
ax.set_ylim(*lims)

ax = axes[1]
lims = [-0.3e-2, 0.5e-2]
plotting.density_scatter(flatten_ij(observables_dict['cij']['train']),
                         flatten_ij(cij),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=30, ax=ax)
ax.set_ylabel('mean-field $C_{ij}$')
ax.set_xlabel('training $C_{ij}$')
ax.plot(lims, lims, 'k')
ax.set_xlim(*lims)
ax.set_ylim(*lims)
ax.ticklabel_format(style='sci', scilimits=(0,0))

fig.tight_layout()
```


![png](notebook_files/meanfield_28_0.png)



```python

```
#### entropies.py

```python
import numpy as np
import pandas as pd

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

mcmc_kwargs = dict(nsteps=1e6, nsample=20, nburnin=1e4)
integration_intervals = 5
L = 9

params = np.load('data/Human_9.npz')
hi_human = params['hi']
Jij_human = params['Jij']

def entropy_thermodynamic_integration(hi, Jij, integration_intervals=1,
        mcmc_kwargs=dict(), prng=np.random):
    F0 = -np.sum(np.log(np.sum(np.exp(hi), axis=1)))
    N, q = hi.shape
    
    jump = lambda x: local_jump(x, q)
    x0 = prng.randint(q, size=N)
    matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, Jij), jump, **mcmc_kwargs)
    energy = np.array([energy_potts(x, hi, Jij) for x in matrix])
    energy_human = np.array([energy_potts(x, hi_human, Jij_human) for x in matrix])
    energy_mean = np.mean(energy)
    deltaE = np.mean(energy_human-energy)
    
    def Fprime(alpha):
        jump = lambda x: local_jump(x, q)
        x0 = prng.randint(q, size=N)
        matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, alpha*Jij), jump, **mcmc_kwargs)
        return np.mean([energy_potts(x, np.zeros_like(hi), Jij) for x in matrix])
    
    xs = np.linspace(0, 1, integration_intervals+1)
    Fprimes = [Fprime(x) for x in xs]
    Fint = scipy.integrate.simps(Fprimes, xs)
   
    F = F0 + Fint
    S = energy_mean - F
    return S, energy_mean, F, deltaE

proteomes = load_proteomes()
if len(sys.argv) < 2:
    print(proteomes.shape[0])
else:
    idx = idx 
    row = proteomes.iloc[idx]
    name = row.name
    path = 'data/%s_%g.npz'%(name, L)
    params = np.load(path)
    hi = params['hi']
    Jij = params['Jij']
    S, E, F, Ehuman = entropy_thermodynamic_integration(hi, Jij,
            integration_intervals=integration_intervals, mcmc_kwargs=mcmc_kwargs)
    with open('data/entropies.csv', 'a') as f:
        f.write(','.join([str(s) for s in [name, S, E, F, Ehuman]]))
        f.write('\n')

```
#### evaluate.py

```python
import os.path
import numpy as np
import pandas as pd

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

for dataset in ['train', 'test', 'model', 'model_global']:
    print(dataset)
    path = 'data/%s_observables.npz'%dataset
    if not os.path.exists(path):
        matrix = load_matrix('data/%s_matrix.csv.gz'%dataset)
        fi = frequencies(matrix, num_symbols=naminoacids)
        fij = pair_frequencies(matrix, num_symbols=naminoacids, fi=fi)
        cij = compute_covariance_matrix(fi, fij)
        fijk = triplet_frequencies(matrix, num_symbols=naminoacids)
        cijk = compute_cijk(fijk, fij, fi)
        fold_ijk = compute_fold_ijk(fijk, fi)
        np.savez_compressed(path,
                 fi=fi, fij=fij, cij=cij,
                 cijk=cijk, fijk=fijk, fold_ijk=fold_ijk)

```
#### fit_all.py

```python
import itertools, json
import numpy as np
import pandas as pd

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

output = True
aas_arr = np.array(list(aminoacids))
L = 9
q = naminoacids
pseudocount = 1e-3
niter = 30
stepsize = 0.1
mcmc_kwargs = dict(nsteps=1e6, nsample=20, nburnin=1e4)

proteomes = load_proteomes()
if len(sys.argv) < 2:
    print(proteomes.shape[0])
else:
    row = proteomes.iloc[int(sys.argv[1])-1]
    name = row.name
    print(name)

    proteome = proteome_path(name)
    matrix = kmers_to_matrix(to_kmers(fasta_iter(proteome, returnheader=False), k=L))
    fi = frequencies(matrix, num_symbols=q, pseudocount=pseudocount)
    fij = pair_frequencies(matrix, num_symbols=q, fi=fi, pseudocount=pseudocount)

    prng = np.random
    def sampler(*args, **kwargs):
        mcmc_kwargs.update(kwargs)
        return mcmcsampler(*args, **mcmc_kwargs)
    hi, Jij = fit_full_potts(fi, fij, sampler=sampler, niter=niter,
                             epsilon=stepsize, prng=prng, output=output)

    np.savez('data/%s_%g.npz'%(name, L), hi=hi, Jij=Jij)

```
#### generate_reference_matrices.py

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

L = 9
seed = 12345

prng = np.random.RandomState(seed=seed)
seqs = np.array(pd.read_csv('../pfam/data/human_nozf.csv')['Sequence'])
train, test = train_test_split(seqs, test_size=0.5, random_state=prng)

for label, data in [('train', train), ('test', test)]:
    matrix = kmers_to_matrix(to_kmers(data, k=L))
    np.savetxt('data/%s_matrix_L%i.csv.gz'%(label,L), matrix, fmt='%i')

```
#### fit.py

```python
import itertools, json
import numpy as np
import pandas as pd

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

from numba import njit

L = 15
nsample = L
output = True
q = naminoacids
pseudocount = 1.0
niter = 30
stepsize = 0.05
nsteps = 1e7
nburnin = 1e3

prng = np.random

matrix = load_matrix('data/train_matrix_L%i.csv.gz'%L)
fi = frequencies(matrix, num_symbols=q, pseudocount=pseudocount)
fij = pair_frequencies(matrix, num_symbols=q, fi=fi, pseudocount=pseudocount)

def sampler(*args, **kwargs):
    return mcmcsampler(*args, nsteps=nsteps, nsample=nsample, nburnin=nburnin)
hi, Jij = fit_full_potts(fi, fij, sampler=sampler, niter=niter,
                         epsilon=stepsize, prng=prng, output=output)

@njit
def jump(x):
    return local_jump_jit(x, q)
@njit
def energy(x):
    return energy_potts(x, hi, Jij)
x0 = prng.randint(q, size=L)
nsteps_generate = int(matrix.shape[0]*nsample)
model_matrix = mcmcsampler(x0, energy, jump, nsteps=nsteps_generate,
                           nsample=nsample, nburnin=nburnin)
np.savetxt('data/model_matrix%i.csv.gz'%L, model_matrix, fmt='%i')

np.savez('data/Human_reference_%i.npz'%L, hi=hi, Jij=Jij)

```
#### plot.py

```python
import numpy as np
import pandas as pd
from matplotlib import colors

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

observables = ['fi', 'cij', 'cijk']
observables_dict = {key: dict() for key in observables}
for dataset in ['train', 'test', 'model', 'model_global']:
    params = np.load('data/%s_observables.npz'%dataset)
    for observable in observables:
        observables_dict[observable][dataset] = params[observable]

for model_type in ['model', 'model_global']:
    fig, axes = plt.subplots(figsize=(6, 3.5), ncols=3, nrows=2)

    for j, (observable, label, lims, flattener) in enumerate([('fi', '$f_i$', (0, 0.12), np.ravel),
                                                   ('cij', '$C_{ij}$', (-0.0025, 0.0035), flatten_ij),
                                                   ('cijk', '$C_{ijk}$', (-4e-4, 7e-4), flatten_ijk)]):
        for i, dataset in enumerate([model_type, 'train']):
            ax = axes[i, j]
            if observable in ['cij', 'cijk']:
                plotting.density_scatter(flattener(observables_dict[observable]['test']),
                                         flattener(observables_dict[observable][dataset]),
                                         norm=colors.LogNorm(vmin=1),
                                         s=0.5,
                                         bins=50, ax=ax)
            else:
                ax.plot(flattener(observables_dict[observable]['test']),
                        flattener(observables_dict[observable][dataset]),
                        'o', ms=2 if observable == 'fi' else 1)

            ax.set_xlabel('test %s'%label)
            ax.set_ylabel('%s %s'%(dataset, label))
            ax.plot(lims, lims, 'k')
            ax.set_xlim(*lims)
            ax.set_ylim(*lims)

    for ax in axes[:, 1:].flatten():
        ax.ticklabel_format(style='sci', scilimits=(0,0))

    fig.tight_layout()

    fig.savefig('main.png' if model_type == 'model' else 'model_global.png')
    if model_type == 'model':
        fig.savefig('../../paper/images/maxent_freqs.pdf')
    else:
        fig.savefig('../../paper/images/maxent_freqs_global.pdf')
    plt.show()
    plt.show()

```
