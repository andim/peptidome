---
layout: post
title: Inference of maxent models
---

Infering and benchmarking of Maxent models.

{% include post-image-gallery.html filter="maxent/" %}

### Code 
#### entropy_analysis.ipynb

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib

import sys
sys.path.append('..')
from lib import *
```


```python
L = 9
q = naminoacids
```


```python
df = pd.read_csv('data/entropies.csv', index_col=0)
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>S</th>
      <th>E</th>
      <th>F</th>
      <th>Ehuman</th>
    </tr>
    <tr>
      <th>name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Human</th>
      <td>25.853997</td>
      <td>-2.590162</td>
      <td>-28.444159</td>
      <td>-2.590162</td>
    </tr>
    <tr>
      <th>Malaria</th>
      <td>24.456549</td>
      <td>-5.282235</td>
      <td>-29.738784</td>
      <td>-2.088056</td>
    </tr>
    <tr>
      <th>Chagas</th>
      <td>25.629811</td>
      <td>-2.977678</td>
      <td>-28.607489</td>
      <td>-2.562489</td>
    </tr>
    <tr>
      <th>Tuberculosis</th>
      <td>24.926774</td>
      <td>-4.600918</td>
      <td>-29.527692</td>
      <td>-2.779992</td>
    </tr>
    <tr>
      <th>Ecoli</th>
      <td>25.818570</td>
      <td>-2.805620</td>
      <td>-28.624189</td>
      <td>-2.277082</td>
    </tr>
  </tbody>
</table>
</div>




```python
Fhuman = df.loc['Human']["F"]
```


```python
df['DKL'] = df['Ehuman']-df['E'] + df['F'] - Fhuman
df['DKL_rand'] = np.log(q)*L-df['S']
```


```python
nats_to_bits = np.log2(np.exp(1))
```


```python
plt.hist(df['S']*nats_to_bits)
plt.axvline(np.log2(q)*L, color='k')
```




    <matplotlib.lines.Line2D at 0x7f49b954e7f0>




![png](notebook_files/entropy_analysis_6_1.png)



```python
df.sort_values('S')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>S</th>
      <th>E</th>
      <th>F</th>
      <th>Ehuman</th>
      <th>DKL</th>
      <th>DKL_rand</th>
    </tr>
    <tr>
      <th>name</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>HBV</th>
      <td>20.290374</td>
      <td>-5.595645</td>
      <td>-25.886019</td>
      <td>-2.412454</td>
      <td>5.741331</td>
      <td>6.671217</td>
    </tr>
    <tr>
      <th>HCV</th>
      <td>23.543850</td>
      <td>-4.021414</td>
      <td>-27.565264</td>
      <td>-2.394171</td>
      <td>2.506137</td>
      <td>3.417740</td>
    </tr>
    <tr>
      <th>HIV</th>
      <td>23.565330</td>
      <td>-3.406392</td>
      <td>-26.971722</td>
      <td>-2.101879</td>
      <td>2.776949</td>
      <td>3.396261</td>
    </tr>
    <tr>
      <th>InfluenzaA</th>
      <td>23.943078</td>
      <td>-3.242337</td>
      <td>-27.185416</td>
      <td>-1.992319</td>
      <td>2.508762</td>
      <td>3.018512</td>
    </tr>
    <tr>
      <th>DENV</th>
      <td>24.066164</td>
      <td>-3.276689</td>
      <td>-27.342853</td>
      <td>-1.953459</td>
      <td>2.424536</td>
      <td>2.895427</td>
    </tr>
    <tr>
      <th>InfluenzaB</th>
      <td>24.403003</td>
      <td>-3.243520</td>
      <td>-27.646523</td>
      <td>-2.059277</td>
      <td>1.981878</td>
      <td>2.558587</td>
    </tr>
    <tr>
      <th>Malaria</th>
      <td>24.456549</td>
      <td>-5.282235</td>
      <td>-29.738784</td>
      <td>-2.088056</td>
      <td>1.899554</td>
      <td>2.505042</td>
    </tr>
    <tr>
      <th>Ebola</th>
      <td>24.530203</td>
      <td>-3.211622</td>
      <td>-27.741825</td>
      <td>-2.166519</td>
      <td>1.747436</td>
      <td>2.431387</td>
    </tr>
    <tr>
      <th>HSV1</th>
      <td>24.893040</td>
      <td>-4.357561</td>
      <td>-29.250601</td>
      <td>-2.804701</td>
      <td>0.746418</td>
      <td>2.068550</td>
    </tr>
    <tr>
      <th>Tuberculosis</th>
      <td>24.926774</td>
      <td>-4.600918</td>
      <td>-29.527692</td>
      <td>-2.779992</td>
      <td>0.737393</td>
      <td>2.034817</td>
    </tr>
    <tr>
      <th>Lyme</th>
      <td>25.006633</td>
      <td>-4.858972</td>
      <td>-29.865605</td>
      <td>-2.398300</td>
      <td>1.039225</td>
      <td>1.954958</td>
    </tr>
    <tr>
      <th>Burkholderia</th>
      <td>25.029332</td>
      <td>-4.291638</td>
      <td>-29.320969</td>
      <td>-2.660384</td>
      <td>0.754443</td>
      <td>1.932259</td>
    </tr>
    <tr>
      <th>EBV</th>
      <td>25.091558</td>
      <td>-3.733864</td>
      <td>-28.825422</td>
      <td>-2.833468</td>
      <td>0.519133</td>
      <td>1.870033</td>
    </tr>
    <tr>
      <th>Leprosy</th>
      <td>25.228458</td>
      <td>-4.073624</td>
      <td>-29.302082</td>
      <td>-2.625925</td>
      <td>0.589776</td>
      <td>1.733132</td>
    </tr>
    <tr>
      <th>Tetanus</th>
      <td>25.304201</td>
      <td>-4.060205</td>
      <td>-29.364406</td>
      <td>-2.303780</td>
      <td>0.836177</td>
      <td>1.657389</td>
    </tr>
    <tr>
      <th>Hpylori</th>
      <td>25.432883</td>
      <td>-3.540561</td>
      <td>-28.973443</td>
      <td>-2.332328</td>
      <td>0.678948</td>
      <td>1.528708</td>
    </tr>
    <tr>
      <th>CMV</th>
      <td>25.585036</td>
      <td>-2.854813</td>
      <td>-28.439849</td>
      <td>-2.448170</td>
      <td>0.410953</td>
      <td>1.376554</td>
    </tr>
    <tr>
      <th>Listeria</th>
      <td>25.625607</td>
      <td>-3.472927</td>
      <td>-29.098534</td>
      <td>-2.302643</td>
      <td>0.515909</td>
      <td>1.335983</td>
    </tr>
    <tr>
      <th>Chagas</th>
      <td>25.629811</td>
      <td>-2.977678</td>
      <td>-28.607489</td>
      <td>-2.562489</td>
      <td>0.251859</td>
      <td>1.331780</td>
    </tr>
    <tr>
      <th>Vaccinia</th>
      <td>25.652124</td>
      <td>-3.102833</td>
      <td>-28.754957</td>
      <td>-1.920291</td>
      <td>0.871744</td>
      <td>1.309467</td>
    </tr>
    <tr>
      <th>StrepA</th>
      <td>25.652853</td>
      <td>-3.392241</td>
      <td>-29.045095</td>
      <td>-2.317461</td>
      <td>0.473844</td>
      <td>1.308737</td>
    </tr>
    <tr>
      <th>Meningococcus</th>
      <td>25.660310</td>
      <td>-3.107576</td>
      <td>-28.767886</td>
      <td>-2.360645</td>
      <td>0.423204</td>
      <td>1.301280</td>
    </tr>
    <tr>
      <th>Yeast</th>
      <td>25.817752</td>
      <td>-2.869042</td>
      <td>-28.686794</td>
      <td>-2.302663</td>
      <td>0.323743</td>
      <td>1.143839</td>
    </tr>
    <tr>
      <th>Ecoli</th>
      <td>25.818570</td>
      <td>-2.805620</td>
      <td>-28.624189</td>
      <td>-2.277082</td>
      <td>0.348507</td>
      <td>1.143021</td>
    </tr>
    <tr>
      <th>Human</th>
      <td>25.853997</td>
      <td>-2.590162</td>
      <td>-28.444159</td>
      <td>-2.590162</td>
      <td>0.000000</td>
      <td>1.107594</td>
    </tr>
    <tr>
      <th>Cattle</th>
      <td>25.876814</td>
      <td>-2.585898</td>
      <td>-28.462712</td>
      <td>-2.543528</td>
      <td>0.023816</td>
      <td>1.084776</td>
    </tr>
    <tr>
      <th>Mouse</th>
      <td>25.881926</td>
      <td>-2.542792</td>
      <td>-28.424718</td>
      <td>-2.537264</td>
      <td>0.024969</td>
      <td>1.079664</td>
    </tr>
    <tr>
      <th>Chicken</th>
      <td>25.920531</td>
      <td>-2.475510</td>
      <td>-28.396040</td>
      <td>-2.480620</td>
      <td>0.043008</td>
      <td>1.041060</td>
    </tr>
    <tr>
      <th>Soybean</th>
      <td>25.975130</td>
      <td>-2.451571</td>
      <td>-28.426700</td>
      <td>-2.309486</td>
      <td>0.159543</td>
      <td>0.986461</td>
    </tr>
    <tr>
      <th>Cockroach</th>
      <td>26.038071</td>
      <td>-2.297132</td>
      <td>-28.335203</td>
      <td>-2.281876</td>
      <td>0.124212</td>
      <td>0.923519</td>
    </tr>
  </tbody>
</table>
</div>




```python
plt.hist(df['DKL'])
```




    (array([14.,  8.,  0.,  3.,  4.,  0.,  0.,  0.,  0.,  1.]),
     array([0.        , 0.57413309, 1.14826618, 1.72239927, 2.29653235,
            2.87066544, 3.44479853, 4.01893162, 4.59306471, 5.1671978 ,
            5.74133089]),
     <a list of 10 Patch objects>)




![png](notebook_files/entropy_analysis_8_1.png)



```python
names = ['Human', 'Mouse', 'Vaccinia', 'InfluenzaB', 'InfluenzaA', 'CMV', 'HCV', 'HSV1',
       'DENV', 'HIV', 'EBV', 'Ebola', 'Ecoli', 'Tuberculosis', 'Listeria',
       'Burkholderia', 'Meningococcus', 'StrepA', 'Hpylori',
       'Lyme', 'Tetanus', 'Leprosy', 'Malaria', 'Chagas']

colors = matplotlib.rcParams['axes.prop_cycle'].by_key()['color']
type_to_color = {'virus' : colors[0],
                 'bacterium' : colors[1],
                 'parasite' : colors[2],
                 'vertebrate' : colors[3],
                 'uniform' : colors[4]
                }
proteomes = load_proteomes()
typecolors = [type_to_color[proteomes.loc[name]['type']] for name in names]
```


```python
df.loc[names].shape, typecolors
```




    (24, 6)




```python
lim = 4.0
ys = df.loc[names]['DKL_rand']
xs = df.loc[names]['DKL']
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(xs, ys, color=typecolors)
ax.plot([0, lim], [0, lim], 'k-')
ax.set_xlabel('$D_{KL}$(proteome $\parallel$ human)')
ax.set_ylabel('$D_{KL}$(proteome $\parallel$ uniform)')
ax.set_aspect('equal')
ax.set_xlim(-0.0, lim)
ax.set_ylim(-0.0, lim)
for i, (type_, color) in enumerate(type_to_color.items()):
    ax.text(0.8, 0.2-i*0.03, type_, color=color, transform=ax.transAxes)
fig.tight_layout()
```


![png](notebook_files/entropy_analysis_11_0.png)



```python

```
#### densityofstates.ipynb

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *
```


```python
params = np.load('data/Human_9.npz')
hi = params['hi']
Jij = params['Jij']
```


```python
datasets = ['train', 'test', 'model']
sample_matrices = {}
for dataset in datasets:
    sample_matrices[dataset] =  np.loadtxt('data/%s_matrix.csv.gz' % dataset).astype(int)
```


```python
observables = ['fi', 'fij', 'cij', 'fijk', 'cijk', 'fold_ijk']#, 'fijkl']
observables_dict = {key: dict() for key in observables}
for dataset in ['train', 'test', 'model']:
    params = np.load('data/%s_observables.npz'%dataset)
    for observable in observables:
        observables_dict[observable][dataset] = params[observable]
```


```python
fi = observables_dict['fi']['train'].mean(axis=0)
sample_independent = np.random.choice(np.arange(0, 20, 1), size=sample_matrices['test'].shape, p=fi)
```


```python
energies_test = np.array([energy_potts(x, hi, Jij) for x in sample_matrices['test']])
energies_model = np.array([energy_potts(x, hi, Jij) for x in sample_matrices['model']])
energies_independent = np.array([energy_potts(x, hi, Jij) for x in sample_independent])
```


```python
bins = np.linspace(-6, 16, 50)
fig, ax = plt.subplots()
ax.hist(-energies_test, bins=bins, histtype='step', label='test')
ax.hist(-energies_independent, bins=bins, histtype='step', label='independent')
ax.hist(-energies_model, bins=bins, histtype='step', label='maxent')
ax.set_yscale('log')
ax.legend()
ax.set_xlabel('-Energy')
ax.set_ylabel('Density')
fig.tight_layout()
fig.savefig('density_of_states.png')
```


![png](notebook_files/densityofstates_6_0.png)



```python
x = sample_matrices['test'][energies_test.argmin()]

```




    array([12, 12, 12, 12, 12, 12, 12, 12, 12])




```python

```
#### entropy_calculation.ipynb

```python
import itertools, json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from matplotlib import colors

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *
```


```python
output = True
N = 9
q = naminoacids

proteome = proteome_path('Human')
seed = 1234
prng = np.random.RandomState(seed)
```


```python
params = np.load('data/Human_full_k9.npz')
hi = params['hi']
Jij = params['Jij']
```


```python
datasets = ['train', 'test', 'model']
sample_matrices = {}
for dataset in datasets:
    sample_matrices[dataset] =  np.loadtxt('data/%s_matrix.csv.gz' % dataset).astype(int)
```


```python
energies = [energy_potts(x, hi, Jij) for x in sample_matrices['model']]
```


```python
F0 = -np.sum(np.log(np.sum(np.exp(hi), axis=1)))
```


```python
def Fprime(alpha):
    jump = lambda x: local_jump(x, q)
    x0 = prng.randint(q, size=N)
    matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, alpha*Jij), jump, 1e6, nsample=10, nburnin=1e3)
    return np.mean([energy_potts(x, np.zeros_like(hi), Jij) for x in matrix])
```


```python
xs = np.linspace(0, 1, 4)
Fprimes = [Fprime(x) for x in xs]
```


```python
Fint = scipy.integrate.simps(Fprimes, xs)
Fint
```




    0.10532807605400357




```python
F0, np.mean(energies), Fint
```




    (-28.01652616764632, -2.072497153551555, 0.10532807605400357)




```python
energies_ind = [energy_potts(x, hi, np.zeros_like(Jij)) for x in independent_matrix]
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-34-b91115b0635f> in <module>
    ----> 1 energies_ind = [energy_potts(x, hi, np.zeros_like(Jij)) for x in independent_matrix]
    

    NameError: name 'independent_matrix' is not defined



```python
np.mean(energies_ind), np.mean(energies)
```


```python
def calc_Sind(hi):
    fis = np.exp(hi)/np.sum(np.exp(hi), axis=1)[:, np.newaxis]
    return np.sum(scipy.stats.entropy(fis.T))
```


```python
Sind = calc_Sind(hi)
S = np.mean(energies) - (F0 + Fint)
S, Sind
```


```python
Sind, np.mean(energies_ind) - F0
```


```python
Suni = np.log2(20)
```


```python
Sind*np.log2(np.exp(1))/N, S*np.log2(np.exp(1))/N
```


```python
df = pd.read_csv('../kmerentropy/data/entropy.csv')
```


```python
np.array(df['Human'])/np.arange(1, 6)
```




    array([4.17756346, 4.16934288, 4.16129658, 4.14931991, 4.11369582])




```python
(Sind-S)*np.log2(np.exp(1))
```




    0.30957087318646137




```python
def entropy_thermodynamic_integration(hi, Jij, integration_intervals=1, mcmc_kwargs=dict()):
    F0 = -np.sum(np.log(np.sum(np.exp(hi), axis=1)))
    N, q = hi.shape
    
    jump = lambda x: local_jump(x, q)
    x0 = prng.randint(q, size=N)
    matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, Jij), jump, **mcmc_kwargs)
    energy_mean = np.mean([energy_potts(x, hi, Jij) for x in matrix])
    
    def Fprime(alpha):
        jump = lambda x: local_jump(x, q)
        x0 = prng.randint(q, size=N)
        matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, alpha*Jij), jump, **mcmc_kwargs)
        return np.mean([energy_potts(x, np.zeros_like(hi), Jij) for x in matrix])
    
    xs = np.linspace(0, 1, integration_intervals+1)
    Fprimes = [Fprime(x) for x in xs]
    Fint = scipy.integrate.simps(Fprimes, xs)
    
    S = energy_mean - (F0 + Fint)
    return S
```


```python
mcmc_kwargs = dict(nsteps=1e6, nsample=10, nburnin=1e3)
```


```python
entropy_thermodynamic_integration(hi, Jij, integration_intervals=3, mcmc_kwargs=mcmc_kwargs)
```




    25.828290270215764




```python

```
#### maxent_analysis.ipynb

```python
import itertools, json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from matplotlib import colors

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

import evcouplings.align, evcouplings.couplings
```


```python
output = True
N = 9
q = naminoacids

proteome = proteome_path('Human')
seed = 1234
prng = np.random.RandomState(seed)
```


```python
params = np.load('data/Human_full_k9.npz')
hi = params['hi']
Jij = params['Jij']
```


```python
datasets = ['train', 'test', 'model']
sample_matrices = {}
for dataset in datasets:
    sample_matrices[dataset] =  np.loadtxt('data/%s_matrix.csv.gz' % dataset).astype(int)
```


    ---------------------------------------------------------------------------

    KeyboardInterrupt                         Traceback (most recent call last)

    <ipython-input-61-498c1022ff5e> in <module>
          2 sample_matrices = {}
          3 for dataset in datasets:
    ----> 4     sample_matrices[dataset] =  np.loadtxt('data/%s_matrix.csv.gz' % dataset).astype(int)
    

    ~/.conda/envs/py3/lib/python3.6/site-packages/numpy/lib/npyio.py in loadtxt(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)
       1157         # converting the data
       1158         X = None
    -> 1159         for x in read_data(_loadtxt_chunksize):
       1160             if X is None:
       1161                 X = np.array(x, dtype)


    ~/.conda/envs/py3/lib/python3.6/site-packages/numpy/lib/npyio.py in read_data(chunk_size)
       1085 
       1086             # Convert each value according to its column and store
    -> 1087             items = [conv(val) for (conv, val) in zip(converters, vals)]
       1088 
       1089             # Then pack it according to the dtype's nesting


    KeyboardInterrupt: 



```python
for dataset in datasets:
    print(dataset, sample_matrices[dataset].shape)
```

    train (5702936, 9)
    test (5646474, 9)
    model (5646474, 9)



```python
fis = {}
fijs = {}
cijs = {}
for dataset in datasets:
    matrix = sample_matrices[dataset]
    fi = frequencies(matrix, num_symbols=q, pseudocount=0.0)
    fis[dataset] = fi
    fij = pair_frequencies(matrix, num_symbols=q, fi=fi, pseudocount=0.0)
    fijs[dataset] = fij
    cij = compute_covariance_matrix(fi=fi, fij=fij)
    cijs[dataset] = cij
```


```python
fijks = {}
for dataset in datasets:
    matrix = sample_matrices[dataset]
    fijk = triplet_frequencies(matrix, num_symbols=q, pseudocount=0.0)
    fijks[dataset] = fijk
```


```python
cijks = {}
for dataset in datasets:
    matrix = sample_matrices[dataset]
    fij = fijs[dataset]
    fi = fis[dataset]
    fijk = fijks[dataset]
    cijk = compute_cijk(fijk, fij, fi)
    cijks[dataset] = cijk
```


```python
plt.plot(flatten_ijk(cijks['test']), flatten_ijk(cijks['train']), 'o', ms=1)
```




    [<matplotlib.lines.Line2D at 0x7fd0b134d588>]




![png](notebook_files/maxent_analysis_8_1.png)



```python
fig, axes = plt.subplots(figsize=(7, 3.5), ncols=2)
for i, dataset in enumerate(['train', 'model']):
    plotting.density_scatter(flatten_ijk(cijks['test']),
                             flatten_ijk(cijks[dataset]),
                             trans=lambda x: np.log(x+1e-3),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i])
    axes[i].set_ylabel(dataset)
for ax in axes:
    max_ = 1.1*flatten_ijk(cijks['test']).max()
    lims = 1/max_, max_
    ax.plot(lims, lims, 'k-')
    ax.set_xscale('log')
    ax.set_yscale('log')
    ax.set_xlabel('test')
    ax.set_xlim(*lims)
    ax.set_ylim(*lims)
fig.tight_layout()
```


![png](notebook_files/maxent_analysis_9_0.png)



```python
jump = lambda x: local_jump(x, q)
x0 = prng.randint(q, size=N)
independent_matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, np.zeros_like(Jij)), jump, 1e7, nsample=10)
```


```python
fi_independent = frequencies(independent_matrix, num_symbols=q, pseudocount=0.0)
fij_independent = pair_frequencies(independent_matrix, num_symbols=q, fi=fi_independent, pseudocount=0.0)
fijk_independent = triplet_frequencies(independent_matrix, num_symbols=q, pseudocount=0.0)
```


```python
cijk_independent = compute_cijk(fijk_independent, fij_independent, fi_independent)
```


```python
plt.plot(flatten_ijk(cijks['test']), flatten_ijk(cijk_independent), 'o', ms=1)
```




    [<matplotlib.lines.Line2D at 0x7fd0b18072b0>]




![png](notebook_files/maxent_analysis_13_1.png)



```python
foldijks = {}
for dataset in datasets:
    fijk = fijks[dataset]
    fi = fis[dataset]
    fold_ijk = fijk / (fi[:, np.newaxis, np.newaxis, :, np.newaxis, np.newaxis] *
                fi[np.newaxis, :, np.newaxis, np.newaxis, :, np.newaxis] *
                fi[np.newaxis, np.newaxis :, np.newaxis, np.newaxis, :])
    foldijks[dataset] = fold_ijk
```


```python
params = np.load('data/Human_full_k9.npz')
hi = params['hi']
Jij = params['Jij']
```


```python
list(zip(aminoacids, hi.std(axis=0)))
```




    [('A', 0.0035406579075383795),
     ('C', 0.0014893643088148595),
     ('D', 0.0013892198615577393),
     ('E', 0.0009110189563667492),
     ('F', 0.0013412697278855862),
     ('G', 0.0014000822211791095),
     ('H', 0.002127311629294183),
     ('I', 0.0020652620217782598),
     ('K', 0.0026846894372483626),
     ('L', 0.0011654184849189324),
     ('M', 0.026951582205213515),
     ('N', 0.0012834177758636997),
     ('P', 0.0009682044299691245),
     ('Q', 0.0013840474784771529),
     ('R', 0.001142693073953028),
     ('S', 0.0009424551613649941),
     ('T', 0.0011721207550945312),
     ('V', 0.0008010794265122387),
     ('W', 0.0014400674267044922),
     ('Y', 0.0022629432493179095)]




```python
observables = ['fi', 'fij', 'cij', 'fijk', 'cijk', 'fold_ijk']#, 'fijkl']
observables_dict = {key: dict() for key in observables}
for dataset in ['train', 'test', 'model']:
    params = np.load('data/%s_observables.npz'%dataset)
    for observable in observables:
        observables_dict[observable][dataset] = params[observable]
```


```python
fig, axes = plt.subplots(figsize=(8, 5), ncols=3, nrows=2)

for j, (observable, label, lims, flattener) in enumerate([('fi', '$f_i$', (0, 0.12), np.ravel),
                                               ('cij', '$C_{ij}$', (-0.0035, 0.0035), flatten_ij),
                                               ('cijk', '$C_{ijk}$', (-8e-4, 8e-4), flatten_ijk)]):
    for i, dataset in enumerate(['model', 'train']):
        ax = axes[i, j]
        if observable == 'cijk':
            plotting.density_scatter(flatten_ijk(observables_dict['cijk']['test']),
                             flatten_ijk(observables_dict['cijk'][dataset]),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i,2])
        else:
            ax.plot(flattener(observables_dict[observable]['test']),
                    flattener(observables_dict[observable][dataset]),
                    'o', ms=1)
        
        ax.set_xlabel('test %s'%label)
        ax.set_ylabel('%s %s'%(dataset, label))
        ax.plot(lims, lims, 'k')
        ax.set_xlim(*lims)
        ax.set_ylim(*lims)

for ax in axes[:, 1:].flatten():
    ax.ticklabel_format(style='sci', scilimits=(0,0))

fig.tight_layout()
```


![png](notebook_files/maxent_analysis_18_0.png)



```python
fig, axes = plt.subplots(figsize=(7, 3.5), ncols=2)
label = r'$\frac{P(\sigma_i, \sigma_j, \sigma_k)}{P(\sigma_i)P(\sigma_j)P(\sigma_k)}$'
for i, dataset in enumerate(['model', 'train']):
    plotting.density_scatter(flatten_ijk(observables_dict['fold_ijk']['test']),
                             flatten_ijk(observables_dict['fold_ijk'][dataset]),
                             trans=lambda x: np.log(x),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i])
    axes[i].set_ylabel('%s %s'%(dataset, label))
for ax in axes:
    ax.set_xlabel('test %s'%label)
    
    max_ = 1.1*flatten_ijk(observables_dict['fold_ijk']['test']).max()
    lims = 1/max_, max_
    ax.plot(lims, lims, 'k-')
    ax.set_xscale('log')
    ax.set_yscale('log')
    ax.set_xlim(*lims)
    ax.set_ylim(*lims)
fig.tight_layout()
fig.savefig('fold.png')
```


![png](notebook_files/maxent_analysis_19_0.png)



```python
fig, axes = plt.subplots(figsize=(7, 3.5), ncols=2)
for i, dataset in enumerate(['model', 'train']):
    indices = 0,4,8
    plotting.density_scatter(observables_dict['fold_ijk']['test'][indices].flatten(),
                             observables_dict['fold_ijk'][dataset][indices].flatten(),
                             trans=lambda x: np.log(x),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i])
    axes[i].set_ylabel(dataset)
for ax in axes:
    max_ = 1.1*observables_dict['fold_ijk']['test'][indices].flatten().max()
    lims = 1/max_, max_
    ax.plot(lims, lims, 'k-')
    ax.set_xscale('log')
    ax.set_yscale('log')
    ax.set_xlabel('test')
    ax.set_xlim(*lims)
    ax.set_ylim(*lims)
fig.tight_layout()
```


![png](notebook_files/maxent_analysis_20_0.png)



```python
fig, axes = plt.subplots(figsize=(7, 3.5), ncols=2)
for i, dataset in enumerate(['model', 'train']):
    if dataset == 'model':
        fi = observables_dict['fi']['train']
        fijk_ind = (fi[:, np.newaxis, np.newaxis, :, np.newaxis, np.newaxis] *
                 fi[np.newaxis, :, np.newaxis, np.newaxis, :, np.newaxis] *
                 fi[np.newaxis, np.newaxis :, np.newaxis, np.newaxis, :])
        test = observables_dict['fijk']['test'][3,4,5,:,:,:].flatten()
        data = fijk_ind[3,4,5,:,:,:].flatten()
        print('ind', calc_jsd(test, data))
        axes[i].plot(test, data, 'o', ms=1)
    test = observables_dict['fijk']['test'][3,4,5,:,:,:].flatten()
    data = observables_dict['fijk'][dataset][3,4,5,:,:,:].flatten()
    print(dataset, calc_jsd(test, data))
    axes[i].plot(test, data, 'o', ms=1)
    axes[i].set_ylabel(dataset)
for ax in axes:
    #max_ = 1.1*flatten_ijk(observables_dict['fijk']['test']).max()
    #lims = 1/max_, max_
    #ax.plot(lims, lims, 'k-')
    ax.set_xscale('log')
    ax.set_yscale('log')
    ax.set_xlabel('test')
    #ax.set_xlim(*lims)
    #ax.set_ylim(*lims)
fig.tight_layout()
```

    ind 0.0073301421024185645
    model 0.0015892616068755262
    train 0.0004770915667735209



![png](notebook_files/maxent_analysis_21_1.png)



```python
fig, axes = plt.subplots(figsize=(7.5, 3.5), ncols=2)
for i, dataset in enumerate(['model', 'train']):
    plotting.density_scatter(flatten_ijk(observables_dict['cijk']['test']),
                             flatten_ijk(observables_dict['cijk'][dataset]),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i])
    axes[i].set_ylabel(dataset + ' $C_{ijk}$')
for ax in axes:
    lim = 7e-4
    lims = -lim, lim
    ax.plot(lims, lims, 'k-')
    ax.set_xlim(*lims)
    ax.set_ylim(*lims)
    ax.set_xlabel('test $C_{ijk}$')
fig.tight_layout()
```


![png](notebook_files/maxent_analysis_22_0.png)



```python
fig, axes = plt.subplots(figsize=(7.5, 3.5), ncols=2)
for i, dataset in enumerate(['model', 'train']):
    indices = 3,4,5
    plotting.density_scatter(observables_dict['cijk']['test'][indices].flatten(),
                             observables_dict['cijk'][dataset][indices].flatten(),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i])
    axes[i].set_ylabel(dataset + ' $C_{ijk}$')
for ax in axes:
    lim = 5e-4
    lims = -lim, lim
    ax.plot(lims, lims, 'k-')
    ax.set_xlim(*lims)
    ax.set_ylim(*lims)
    ax.set_xlabel('test $C_{ijk}$')
fig.tight_layout()
```


![png](notebook_files/maxent_analysis_23_0.png)



```python

```
#### meanfield.ipynb

```python
import itertools, json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from matplotlib import colors

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

import evcouplings.couplings
```


```python
params = np.load('data/Human_9.npz')
hi = params['hi']
Jij = params['Jij']
```


```python
L, q = hi.shape
L, q
```




    (9, 20)




```python
observables = ['fi', 'fij', 'cij', 'fijk', 'cijk', 'fold_ijk']#, 'fijkl']
observables_dict = {key: dict() for key in observables}
for dataset in ['train', 'test', 'model']:
    params = np.load('data/%s_observables.npz'%dataset)
    for observable in observables:
        observables_dict[observable][dataset] = params[observable]
```


```python
@numba.jit(nopython=True)
def _flatten_index(i, alpha, q):
    """
    Map position and symbol to index in
    the covariance matrix.
    Parameters
    ----------
    i : int, np.array of int
        The alignment column(s).
    alpha : int, np.array of int
        The symbol(s).
    q : int
        The number of symbols of the
        alphabet used.
    """
    return i * (q - 1) + alpha
```


```python
@numba.jit(nopython=True)
def reshape_invcov_to_4d(inv_cov_matrix, L, q):
    """
    "Un-flatten" flattened covariance matrix
    
    Parameters
    ----------
    inv_cov_matrix : np.array
        The matrix to be flattened
    L : int
        Model length.
    q : int
        Number of characters in the alphabet.
    Returns
    -------
    np.array
        Matrix of size L x L x
        q x q.
    """
    inv = np.zeros((L, L, q, q))
    for i in range(L):
        for j in range(L):
            for alpha in range(q - 1):
                for beta in range(q - 1):
                    inv[i, j, alpha, beta] = inv_cov_matrix[
                        _flatten_index(i, alpha, q),
                        _flatten_index(j, beta, q)
                    ]
    return inv
```


```python
def compute_Jij_mf(cij_flat):
    invC = np.linalg.inv(cij_flat)
    Jij = -reshape_invcov_to_4d(invC, L, q)
    return Jij
```


```python
@numba.jit(nopython=True)
def fields(J_ij, f_i):
    """
    Compute fields in q gauge.
    
    Parameters
    ----------
    J_ij : np.array
        Matrix of size L x L x q x q
        containing coupling parameters.
    f_i : np.array
        Matrix of size L x q
        containing single-site frequencies.
    Returns
    -------
    np.array
        Matrix of size L x q
        containing single-site fields.
    """
    L, q = f_i.shape
    hi = np.zeros((L, q))
    for i in range(L):
        log_fi = np.log(f_i[i] / f_i[i, q-1])
        J_ij_sum = np.zeros((1, q))
        for j in range(L):
            if i != j:
                # some eij values over beta from 1 to q-1
                J_ij_sum += np.dot(J_ij[i, j, :, :q-1], f_i[j, :q-1]).T
        hi[i] = log_fi - J_ij_sum
    return hi
```


```python
fi = observables_dict['fi']['train']
fij = observables_dict['fij']['train']
alpha = 1e-8
fi_reg = (1-alpha)*fi + alpha/q
fij_reg = (1-alpha)*fij + alpha/q**2
cij_flat = compute_flattened_covariance_matrix(fi_reg, fij_reg)
Jij_mf = compute_Jij_mf(cij_flat)
hi_mf = fields(Jij_mf, fi_reg)
```

    <ipython-input-8-c53c1d109231>:28: NumbaPerformanceWarning: [1m[1mnp.dot() is faster on contiguous arrays, called on (array(float64, 2d, A), array(float64, 1d, C))[0m[0m
      J_ij_sum += np.dot(J_ij[i, j, :, :q-1], f_i[j, :q-1]).T



```python
def zero_sum_gauge(J_ij):
    J_ij_0 = (J_ij
              - np.mean(J_ij, axis=2)[:, :, np.newaxis, :]
              - np.mean(J_ij, axis=3)[:, :, :, np.newaxis]
              + np.mean(J_ij, axis=(2,3))[:, :, np.newaxis, np.newaxis])
    return J_ij_0
```


```python
L, q = fi.shape
rhoij = np.zeros(fij.shape)
for i in range(L):
    for j in range(L):
        rhoij[i, j] = fij[i, j]/np.outer(fi[i], fi[j]) - 1.0
plt.plot(flatten_ij(rhoij), flatten_ij(zero_sum_gauge(Jij)),
         '.', ms=1, label='fitted')
plt.plot(flatten_ij(rhoij), flatten_ij(zero_sum_gauge(Jij_mf)),
         '.', ms=1, label='mf')
lim = 1.0
plt.plot([-lim, lim], [-lim, lim], 'k-')
plt.xlabel(r'$\rho_{ij}$')
plt.ylabel('$J_{ij}$')
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f334ea99748>




![png](notebook_files/meanfield_10_1.png)



```python
bins = np.linspace(-1, 1, 20)
plt.hist(flatten_ij(zero_sum_gauge(Jij)), bins=bins, histtype='step')
plt.hist(flatten_ij(zero_sum_gauge(Jij_mf)), bins=bins, histtype='step');
```


![png](notebook_files/meanfield_11_0.png)



```python
Jij_mf_zero = zero_sum_gauge(Jij_mf)
hi_mf_zero = fields(Jij_mf_zero, fi)
```


```python
prng = np.random
jump = lambda x: local_jump(x, q)
x0 = prng.randint(q, size=L)
sample_matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi_mf, Jij_mf), jump, 1e6, nsample=100, nburnin=1e4)
```


```python
fi_mf = frequencies(sample_matrix, num_symbols=q)
fij_mf = pair_frequencies(sample_matrix, num_symbols=q, fi=fi_mf)
cij_mf = compute_covariance_matrix(fi_mf, fij_mf)
```


```python
fig, axes = plt.subplots(figsize=(7, 3.2), ncols=2)

ax = axes[0]
lims = [0, 0.12]
ax.plot(np.ravel(fi), np.ravel(fi_mf), 'o', ms=2)
ax.set_xlabel('training $f_i$')
ax.set_ylabel('mf $f_i$')
ax.plot(lims, lims, 'k')
ax.set_xlim(*lims)
ax.set_ylim(*lims)

ax = axes[1]
lims = [-0.3e-2, 1.5e-2]
ax.plot(flatten_ij(observables_dict['cij']['train']), flatten_ij(cij_mf), 'o', ms=2)
ax.set_ylabel('mean-field $C_{ij}$')
ax.set_xlabel('training $C_{ij}$')
ax.plot(lims, lims, 'k')
ax.set_xlim(*lims)
ax.set_ylim(*lims)
ax.ticklabel_format(style='sci', scilimits=(0,0))

fig.tight_layout()
fig.savefig('meanfield.png')
```


![png](notebook_files/meanfield_15_0.png)



```python
invC = np.linalg.inv(cij_flat)
invC4d = reshape_invcov_to_4d(invC, L, q)
Jij_TAP = -2*invC4d/(1+(1-8*invC4d*fi[:, np.newaxis, :, np.newaxis]*fi[np.newaxis, :, np.newaxis, :])**.5)
```

    /home/amayer/.conda/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in sqrt
      This is separate from the ipykernel package so we can avoid doing imports until



```python
flatten_ij(Jij_TAP).mean(), flatten_ij(Jij_mf).mean()
```




    (0.19261893913664105, 0.1930600243824052)




```python
plt.hist(flatten_ij(Jij_TAP));
```


![png](notebook_files/meanfield_18_0.png)



```python
plt.plot(flatten_ij(Jij_mf), flatten_ij(Jij_TAP), 'o')
plt.plot([-1, 3], [-1, 3])
```




    [<matplotlib.lines.Line2D at 0x7f335ebbae80>]




![png](notebook_files/meanfield_19_1.png)



```python
L, q = fi.shape
rhoij = np.zeros(fij.shape)
for i in range(L):
    for j in range(L):
        rhoij[i, j] = fij[i, j]/np.outer(fi[i], fi[j]) - 1.0
plt.plot(flatten_ij(rhoij), flatten_ij(zero_sum_gauge(Jij)),
         '.', ms=1, label='fitted')
plt.plot(flatten_ij(rhoij), flatten_ij(zero_sum_gauge(Jij_TAP)),
         '.', ms=1, label='mf')
lim = 1.0
plt.plot([-lim, lim], [-lim, lim], 'k-')
plt.xlabel(r'$\rho_{ij}$')
plt.ylabel('$J_{ij}$')
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f335ed1a2e8>




![png](notebook_files/meanfield_20_1.png)



```python

```
#### entropies.py

```python
import numpy as np
import pandas as pd

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

mcmc_kwargs = dict(nsteps=1e6, nsample=20, nburnin=1e4)
integration_intervals = 5
L = 9

params = np.load('data/Human_9.npz')
hi_human = params['hi']
Jij_human = params['Jij']

def entropy_thermodynamic_integration(hi, Jij, integration_intervals=1,
        mcmc_kwargs=dict(), prng=np.random):
    F0 = -np.sum(np.log(np.sum(np.exp(hi), axis=1)))
    N, q = hi.shape
    
    jump = lambda x: local_jump(x, q)
    x0 = prng.randint(q, size=N)
    matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, Jij), jump, **mcmc_kwargs)
    energy = np.array([energy_potts(x, hi, Jij) for x in matrix])
    energy_human = np.array([energy_potts(x, hi_human, Jij_human) for x in matrix])
    energy_mean = np.mean(energy)
    deltaE = np.mean(energy_human-energy)
    
    def Fprime(alpha):
        jump = lambda x: local_jump(x, q)
        x0 = prng.randint(q, size=N)
        matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, alpha*Jij), jump, **mcmc_kwargs)
        return np.mean([energy_potts(x, np.zeros_like(hi), Jij) for x in matrix])
    
    xs = np.linspace(0, 1, integration_intervals+1)
    Fprimes = [Fprime(x) for x in xs]
    Fint = scipy.integrate.simps(Fprimes, xs)
   
    F = F0 + Fint
    S = energy_mean - F
    return S, energy_mean, F, deltaE

proteomes = load_proteomes()
if len(sys.argv) < 2:
    print(proteomes.shape[0])
else:
    idx = idx 
    row = proteomes.iloc[idx]
    name = row.name
    path = 'data/%s_%g.npz'%(name, L)
    params = np.load(path)
    hi = params['hi']
    Jij = params['Jij']
    S, E, F, Ehuman = entropy_thermodynamic_integration(hi, Jij,
            integration_intervals=integration_intervals, mcmc_kwargs=mcmc_kwargs)
    with open('data/entropies.csv', 'a') as f:
        f.write(','.join([str(s) for s in [name, S, E, F, Ehuman]]))
        f.write('\n')

```
#### evaluate.py

```python
import itertools, json
import numpy as np
import pandas as pd

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

for dataset in ['train', 'test', 'model']:
    matrix = np.loadtxt('data/%s_matrix.csv.gz'%dataset).astype(int)
    fi = frequencies(matrix, num_symbols=naminoacids)
    fij = pair_frequencies(matrix, num_symbols=naminoacids, fi=fi)
    cij = compute_covariance_matrix(fi, fij)
    fijk = triplet_frequencies(matrix, num_symbols=naminoacids)
    cijk = compute_cijk(fijk, fij, fi)
    fold_ijk = compute_fold_ijk(fijk, fi)
    np.savez('data/%s_observables.npz'%dataset,
             fi=fi, fij=fij, cij=cij,
             cijk=cijk, fijk=fijk, fold_ijk=fold_ijk)

```
#### fit_all.py

```python
import itertools, json
import numpy as np
import pandas as pd

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

output = True
aas_arr = np.array(list(aminoacids))
L = 9
q = naminoacids
pseudocount = 1e-3
niter = 30
stepsize = 0.1
mcmc_kwargs = dict(nsteps=1e6, nsample=20, nburnin=1e4)
seed = 1234

proteomes = load_proteomes()
if len(sys.argv) < 2:
    print(proteomes.shape[0])
else:
    row = proteomes.iloc[int(sys.argv[1])-1]
    name = row.name
    print(name)

    proteome = proteome_path(name)
    seqs = [s for s in fasta_iter(proteome, returnheader=False)]
    arr =  np.array([list(kmer) for kmer in to_kmers(seqs, k=L)])
    matrix = map_matrix(arr, map_)
    fi = frequencies(matrix, num_symbols=q, pseudocount=pseudocount)
    fij = pair_frequencies(matrix, num_symbols=q, fi=fi, pseudocount=pseudocount)

    prng = np.random.RandomState(seed)
    def sampler(*args, **kwargs):
        mcmc_kwargs.update(kwargs)
        return mcmcsampler(*args, **mcmc_kwargs)
    hi, Jij = fit_full_potts(fi, fij, sampler=sampler, niter=niter,
                             epsilon=stepsize, prng=prng, output=output)

    np.savez('data/%s_%g.npz'%(name, L), hi=hi, Jij=Jij)

```
#### fit.py

```python
import itertools, json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

output = True
N = 9
q = naminoacids
niter = 50
stepsize = 0.1
nsample = N
nsteps = 5e7

proteome = proteome_path('Human')
seed = 1234
prng = np.random.RandomState(seed)

seqs = [s for s in fasta_iter(proteome, returnheader=False)]
train, test = train_test_split(seqs, test_size=0.5, random_state=prng)

for label, data in [('train', train), ('test', test)]:
    arr =  np.array([list(kmer) for kmer in to_kmers(data, k=N)])
    matrix = map_matrix(arr, map_)
    np.savetxt('data/%s_matrix.csv.gz'%label, matrix, fmt='%i')
    if label == 'train':
        fi = frequencies(matrix, num_symbols=q, pseudocount=1e-3)
        fij = pair_frequencies(matrix, num_symbols=q, fi=fi, pseudocount=1e-3)

def sampler(*args, **kwargs):
    return mcmcsampler(*args, nsteps=nsteps, nsample=nsample, **kwargs)
hi, Jij = fit_full_potts(fi, fij, sampler=sampler, niter=niter,
                         epsilon=stepsize, prng=prng, output=output)

jump = lambda x: local_jump(x, q)
x0 = prng.randint(q, size=N)
nsteps_generate = int(matrix.shape[0]*nsample)
model_matrix = mcmcsampler(x0, lambda x: energy_potts(x, hi, Jij), jump,
                           nsteps=nsteps_generate, nsample=nsample, prng=prng)
np.savetxt('data/model_matrix.csv.gz', model_matrix, fmt='%i')

np.savez('data/Human_full_k%g.npz'%N, hi=hi, Jij=Jij)

```
#### plot.py

```python
import itertools, json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from matplotlib import colors

import sys
sys.path.append('..')
from lib import *
from lib.maxent import *

import evcouplings.align, evcouplings.couplings

observables = ['fi', 'fij', 'cij', 'fijk', 'cijk', 'fold_ijk']#, 'fijkl']
observables_dict = {key: dict() for key in observables}
for dataset in ['train', 'test', 'model']:
    params = np.load('data/%s_observables.npz'%dataset)
    for observable in observables:
        observables_dict[observable][dataset] = params[observable]

fig, axes = plt.subplots(figsize=(8, 5), ncols=3, nrows=2)

for j, (observable, label, lims, flattener) in enumerate([('fi', '$f_i$', (0, 0.12), np.ravel),
                                               ('cij', '$C_{ij}$', (-0.0035, 0.0035), flatten_ij),
                                               ('cijk', '$C_{ijk}$', (-7e-4, 7e-4), flatten_ijk)]):
    for i, dataset in enumerate(['model', 'train']):
        ax = axes[i, j]
        if observable == 'cijk':
            plotting.density_scatter(flatten_ijk(observables_dict['cijk']['test']),
                             flatten_ijk(observables_dict['cijk'][dataset]),
                             norm=colors.LogNorm(vmin=1),
                             s=0.5,
                             bins=50, ax=axes[i,2])
        else:
            ax.plot(flattener(observables_dict[observable]['test']),
                    flattener(observables_dict[observable][dataset]),
                    'o', ms=2 if observable == 'fi' else 1)

        ax.set_xlabel('test %s'%label)
        ax.set_ylabel('%s %s'%(dataset, label))
        ax.plot(lims, lims, 'k')
        ax.set_xlim(*lims)
        ax.set_ylim(*lims)

for ax in axes[:, 1:].flatten():
    ax.ticklabel_format(style='sci', scilimits=(0,0))

fig.tight_layout()
fig.savefig('main.png')
plt.show()

```
