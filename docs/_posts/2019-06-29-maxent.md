---
layout: post
title: Inference of maxent models
---

Infering and benchmarking of Maxent models.

{% include post-image-gallery.html filter="maxent/" %}

### Code 
#### generic.ipynb


# Maximum entropy modeling

We consider a distribution $P(\boldsymbol \sigma)$, where $\boldsymbol \sigma$ is an N-dimensional state vector. We search for the distribution which maximizes the entropy subject to some constraints on the expectation value of a (smallish) number of observables:

$$\langle \sum_{\boldsymbol \sigma} P(\boldsymbol \sigma) f_\mu(\boldsymbol \sigma)\rangle = f_\mu^{emp}$$

Using the method of Lagrange multipliers we can show that the distributions take the form:

$$P(\boldsymbol \sigma) = \frac{1}{Z} \exp\left[ -\sum_\mu \lambda_\mu f_\mu(\boldsymbol \sigma) \right]$$



```python
import numpy as np
import matplotlib.pyplot as plt
import sys
sys.path.append('..')
from lib import *
%matplotlib inline
```


```python
class MaxEntModel:
    def __init__(self, N, q, constraints, prng=None):
        """
        N: number of spins
        q: number of possible spin states
        constraints: list of constraints
        """
        self.N = N
        self.q = q
        self.constraints = constraints
        self.lambdas = np.zeros_like(constraints)
        if prng is None:
            self.prng = np.random
        else:
            self.prng = prng
    def energy(self, sigma):
        return np.sum(self.lambdas * np.array([c(sigma) for c in self.constraints]))
    def sample(self, n):
        'n: number of samples'
        def jump(x):
            return self.prng.randint(self.q, size=self.N)
        x0 = jump(np.zeros(self.N))
        return mcmcsampler(x0, self.energy, jump, n)
```


```python
def gen_field_constraint(index):
    def constraint(x):
        return x[index]
    return constraint
```


```python
m = MaxEntModel(5, 2, [gen_field_constraint(i) for i in range(5)])
m.lambdas = np.array([0.1, 0.2, 0.3, -0.1, -0.3])
m.energy([0, 1, 1, 0, 0])
```




    0.5




```python
m.sample(10)
```




    array([[0, 1, 0, 0, 0],
           [1, 0, 0, 1, 1],
           [1, 0, 0, 1, 1],
           [1, 0, 1, 1, 0],
           [1, 1, 1, 0, 1],
           [0, 1, 0, 1, 0],
           [1, 1, 1, 1, 0],
           [0, 0, 0, 1, 0],
           [1, 1, 0, 1, 1]])




```python

```
#### mfmaxent.ipynb



```python
import itertools, copy
import json
import numpy as np
import scipy.misc
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

import evcouplings.align, evcouplings.couplings

from lib import *
```


```python
counter = count_kmers_proteome(human, 9)
```


```python
df = counter_to_df(counter, norm=False)
```


```python
seqmat = np.random.choice(df['seq'], p=df['count']/np.sum(df['count']), size=1000000)
seqmat = np.array([list(seq) for seq in seqmat])
seqmat
```




    array([['L', 'E', 'T', ..., 'L', 'S', 'K'],
           ['E', 'P', 'A', ..., 'A', 'E', 'E'],
           ['D', 'R', 'K', ..., 'S', 'K', 'I'],
           ...,
           ['E', 'G', 'Q', ..., 'P', 'T', 'D'],
           ['P', 'S', 'S', ..., 'P', 'S', 'K'],
           ['V', 'D', 'L', ..., 'G', 'Y', 'M']], dtype='<U1')




```python
map_ = map_ = {c: i for i, c in enumerate(aminoacids)}
mapped_seqmat = evcouplings.align.map_matrix(seqmat, map_)
```


```python
fi = evcouplings.align.frequencies(mapped_seqmat, np.ones(len(seqmat)), num_symbols=len(aminoacids))
```


```python
plt.plot(fi);
```


![png](notebook_files/mfmaxent_6_0.png)



```python
fij = evcouplings.align.pair_frequencies(mapped_seqmat, np.ones(len(seqmat)), num_symbols=len(aminoacids), fi=fi)
```


```python
cij = evcouplings.couplings.compute_covariance_matrix(fi, fij)
```


```python
invC = np.linalg.inv(cij)
```


```python
Jij = evcouplings.couplings.reshape_invC_to_4d(invC,
                seqmat.shape[1],
                len(aminoacids))
```


```python
Jij_zerogauge = evcouplings.couplings.model._zero_sum_gauge(Jij)
```


```python
Jij.shape, hi.shape
```




    ((9, 9, 20, 20), (9, 20))




```python
hi = evcouplings.couplings.fields(Jij, fi)
print(hi)

#for i in range(hi.shape[0]):
#    for a in range(hi.shape[1]):
#        hi[i, a] += np.sum(Jij[i, :, a, :])
```

    [[-1.54358693 -2.07270845 -0.80468815 -1.41752994 -0.63186966 -0.92155894
      -1.56749297 -0.82109498 -1.1076127  -0.76008308 -2.05347801 -1.13541913
      -1.74335556 -1.66874481 -1.21077571 -1.35028734 -1.24097355 -1.20268742
      -2.66716701  0.        ]
     [-2.02628489 -2.37619276 -1.213346   -1.9183758  -0.75214758 -1.24382222
      -1.77635364 -1.25914133 -1.62692754 -1.19852467 -2.31519811 -1.35516518
      -2.05696404 -1.93688219 -1.78411355 -1.61970629 -1.62946167 -1.71629358
      -2.92718915  0.        ]
     [-1.64667488 -1.5755443  -0.68724974 -1.45512976 -0.45754653 -0.94936954
      -1.40425576 -0.8966046  -1.10688796 -0.9505373  -1.64225758 -0.86318387
      -1.66892635 -1.55584482 -1.23878323 -1.35729861 -1.23175403 -1.26107095
      -2.60779649  0.        ]
     [-1.8559691  -1.55620142 -0.83387965 -1.59795891 -0.80750258 -1.08214028
      -1.82357292 -1.01721964 -1.21589382 -1.04060444 -1.77854664 -0.83491727
      -1.78616235 -1.78487647 -1.48466656 -1.47614323 -1.55216619 -1.59166288
      -2.29090254  0.        ]
     [-1.74089215 -1.39300893 -0.83224836 -1.40025297 -0.6586081  -0.98545041
      -1.48260477 -0.70327042 -1.18590553 -0.85659555 -1.68445069 -0.78245731
      -1.79120149 -1.65359867 -1.33764298 -1.28670192 -1.43735745 -1.04075397
      -2.42956518  0.        ]
     [-1.57163211 -0.88195277 -0.64777293 -1.1859494  -0.49900998 -1.02730853
      -1.37469212 -0.77305707 -0.93166396 -0.77906525 -1.49390646 -0.59074722
      -1.67443358 -1.48102499 -1.12127843 -0.99312035 -1.34917528 -0.97206871
      -2.10167532  0.        ]
     [-1.87939667 -1.02070877 -0.94372008 -1.4941349  -0.75051128 -1.10295969
      -1.76061435 -0.83020553 -1.11023346 -1.05155874 -1.71463791 -0.73065698
      -1.92365548 -1.69870713 -1.11938935 -1.32194779 -1.66290774 -1.17681909
      -2.515543    0.        ]
     [-1.71751161 -0.84789991 -0.75128915 -1.29303116 -0.71685286 -1.10642173
      -1.47927176 -0.93830258 -1.0698637  -0.82950716 -1.75027209 -0.66667921
      -1.69156696 -1.68810524 -1.24941928 -1.13866877 -1.40504312 -1.03488636
      -2.04676636  0.        ]
     [-1.64622305 -1.00496553 -0.87446159 -1.37982719 -0.85508811 -1.23844428
      -1.71393182 -1.21879337 -1.13652311 -0.92123978 -1.91600569 -0.86896287
      -1.84796423 -1.80510358 -1.36442105 -1.33998879 -1.50921132 -1.31613662
      -2.20215439  0.        ]]



```python
plt.plot([np.abs(Jij_zerogauge[0, i]).sum() for i in range(1,seqmat.shape[1])])
```




    [<matplotlib.lines.Line2D at 0x7f27f1f324a8>]




![png](notebook_files/mfmaxent_14_1.png)



```python
import numba
@numba.jit(nopython=True)
def energy_ising(x, hi, Jij):
    e = 0
    for i in range(len(x)):
        e += hi[i, x[i]]
    for i in range(len(x)):
        for j in range(i+1, len(x)):
            e += Jij[i, j, x[i], x[j]]
    return -e
```


```python
jump = lambda x: ''.join(np.random.choice(list(aminoacids), size=9))
x0 = jump(0)
samples = mcmcsampler(x0, lambda x: energy_ising(evcouplings.align.map_matrix(list(x), map_),
                                                 np.log(fi), -Jij_zerogauge), jump, 1e6)
```


```python
fi_model = evcouplings.align.frequencies(evcouplings.align.map_matrix([list(s) for s in samples], map_), np.ones(len(samples)), num_symbols=len(aminoacids))
```


```python
fij_model = evcouplings.align.pair_frequencies(evcouplings.align.map_matrix([list(s) for s in samples], map_), np.ones(len(samples)), num_symbols=len(aminoacids), fi=fi_model)
```


```python
plt.plot(fi.flatten(), fi_model.flatten(), 'o')
```




    [<matplotlib.lines.Line2D at 0x7fbc09da23c8>]




![png](notebook_files/mfmaxent_19_1.png)



```python
cij_model = evcouplings.couplings.compute_covariance_matrix(fi_model, fij_model).flatten()
```


```python
plt.plot(cij.flatten(), cij_model.flatten(), 'o')
plt.xlim(-0.01, 0.01) 
plt.ylim(-0.01, 0.01)
```




    (-0.01, 0.01)




![png](notebook_files/mfmaxent_21_1.png)



```python
plt.imshow(Jij_zerogauge[0,3])
plt.colorbar()
```




    <matplotlib.colorbar.Colorbar at 0x7f27f146e630>




![png](notebook_files/mfmaxent_22_1.png)



```python
cij_reshaped = evcouplings.couplings.reshape_invC_to_4d(cij,
                seqmat.shape[1],
                len(aminoacids))
```


```python
plt.imshow(np.log(cij))
plt.colorbar()
```

    /home/amayer/.conda/envs/immune/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log
      """Entry point for launching an IPython kernel.





    <matplotlib.colorbar.Colorbar at 0x7f27e28229e8>




![png](notebook_files/mfmaxent_24_2.png)



```python
evcouplings.couplings.fields(Jij, fi)
```




    array([[-0.58948613, -1.49454664, -0.06356165, -0.66337832, -0.2171583 ,
            -0.20599974, -1.12149109, -0.34826784, -0.4652226 , -0.18996467,
            -1.20533431, -0.3586272 , -0.82946664, -0.89649406, -0.57285944,
            -0.54598427, -0.48298814, -0.49362122, -1.92228331,  0.        ],
           [-1.12351143, -1.54950611, -0.49046486, -0.88549072, -0.31541571,
            -0.53927169, -1.3333736 , -0.67071048, -0.59192545, -0.34619445,
            -1.37216552, -0.71211838, -1.06653231, -1.14273861, -0.60002826,
            -0.70608306, -0.8707877 , -0.7707656 , -2.26722117,  0.        ],
           [-1.03143766, -0.90326623, -0.49892468, -0.77711307, -0.3381534 ,
            -0.57145138, -1.27959186, -0.33247223, -0.5609431 , -0.32427995,
            -1.58490899, -0.53115011, -1.0159358 , -0.92859568, -0.65171482,
            -0.57381468, -0.82887568, -0.58381621, -1.89875207,  0.        ],
           [-1.08447151, -0.8175469 , -0.4356856 , -0.77175087, -0.35510648,
            -0.65782131, -1.2214273 , -0.48076711, -0.46544313, -0.26750341,
            -1.22623991, -0.2997465 , -0.97578942, -0.83885123, -0.50284352,
            -0.52583959, -0.79188462, -0.56738717, -1.79200991,  0.        ],
           [-1.2961166 , -0.93947583, -0.72340868, -0.92631677, -0.55577192,
            -0.86051182, -1.17710344, -0.57838489, -0.91560776, -0.41434509,
            -1.51472252, -0.7042204 , -1.30813338, -1.09782102, -1.00434325,
            -0.70433519, -1.09790819, -0.63944634, -1.95269353,  0.        ],
           [-1.05426183, -0.19133565, -0.45347017, -0.58283641, -0.57146287,
            -0.53213732, -1.16309238, -0.5629099 , -0.65395116, -0.21944314,
            -1.31402439, -0.45590557, -1.09667765, -0.95207544, -0.72080053,
            -0.54169284, -0.86759949, -0.43545659, -1.82313135,  0.        ]])




```python
alignment = evcouplings.align.Alignment(seqmat,
                                        sequence_ids=[str(i)+'/1-4' if i == 0 else '' for i in range(len(seqmat))],
                                        alphabet=evcouplings.align.ALPHABET_PROTEIN_NOGAP)
```


    ---------------------------------------------------------------------------

    KeyError                                  Traceback (most recent call last)

    ~/.conda/envs/immune/lib/python3.7/site-packages/evcouplings/align/alignment.py in map_from_alphabet(alphabet, default)
        458     try:
    --> 459         default = map_[default]
        460     except KeyError:


    KeyError: '-'

    
    During handling of the above exception, another exception occurred:


    ValueError                                Traceback (most recent call last)

    <ipython-input-111-f047e6e5b7b7> in <module>
          1 alignment = evcouplings.align.Alignment(seqmat,
          2                                         sequence_ids=[str(i)+'/1-4' if i == 0 else '' for i in range(len(seqmat))],
    ----> 3                                         alphabet=evcouplings.align.ALPHABET_PROTEIN_NOGAP)
    

    ~/.conda/envs/immune/lib/python3.7/site-packages/evcouplings/align/alignment.py in __init__(self, sequence_matrix, sequence_ids, annotation, alphabet)
        539 
        540         self.alphabet_map = map_from_alphabet(
    --> 541             self.alphabet, default=self.alphabet_default
        542         )
        543         self.num_symbols = len(self.alphabet_map)


    ~/.conda/envs/immune/lib/python3.7/site-packages/evcouplings/align/alignment.py in map_from_alphabet(alphabet, default)
        460     except KeyError:
        461         raise ValueError(
    --> 462             "Default {} is not in alphabet {}".format(default, alphabet)
        463         )
        464 


    ValueError: Default - is not in alphabet ACDEFGHIKLMNPQRSTVWY



```python
mfdca = evcouplings.couplings.MeanFieldDCA(alignment)
```


```python
fit = mfdca.fit(pseudo_count=0.5)
```


```python
fit.J_ij.shape
```




    (4, 4, 21, 21)




```python
plt.imshow(evcouplings.couplings.model._zero_sum_gauge(fit.J_ij)[0, 1])
plt.colorbar()
```




    <matplotlib.colorbar.Colorbar at 0x7f27e1c140b8>




![png](notebook_files/mfmaxent_30_1.png)



```python

```
#### energy-benchmarking.ipynb



```python
import copy 
import numpy as np
import matplotlib.pyplot as plt
import sys
sys.path.append('..')
from lib import *
%matplotlib inline
%load_ext Cython
```


```python
q = 20
N = 10
h = np.zeros(q)
J = np.zeros((N-1, q, q))
```


```python
def energy_fast(s, h, J):
    energy = np.sum(h[s])
    for i in range(N):
        for j in range(i, N):
            energy += J[j-i-1, s[i], s[j]]
    return energy
```


```python
%%timeit
s = np.random.randint(q, size=N)
energy_fast(s, h, J)
```

    33.9 µs ± 799 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)



```cython
%%cython
cimport numpy as np
def energy_cython(np.ndarray[long, ndim=1] s, np.ndarray[double, ndim=1] h, np.ndarray[double, ndim=3] J):
    cdef int N = len(s)
    cdef double energy = 0.0
    cdef int i, j
    for i in range(N):
        energy += h[s[i]]
        for j in range(i, N):
            energy += J[j-i-1, s[i], s[j]]
    return energy
```


```python
%%timeit
s = np.random.randint(q, size=N)
energy_cython(s, h, J)
```

    2.91 µs ± 38.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)



```python
aas_arr = np.array(list(aminoacids))
h = dict(zip(aminoacids, np.zeros(q)))
J0 = np.zeros((len(aminoacids), len(aminoacids)))
J0 = pd.DataFrame(np.asarray(J0), index=list(aminoacids), columns=list(aminoacids)).to_dict()
Jk = [J0]
for gap in range(1, N):
    Jk.append(copy.deepcopy(J0))

```


```python
%%timeit
s = ''.join(np.random.choice(aas_arr, size=N))
energy_ising(s, h, Jk)
```

    33.7 µs ± 2.31 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)



```python
s = np.random.randint(q, size=N)
s
```




    array([ 0, 16, 11,  7, 17, 12, 16,  3, 11,  1])




```python
''.join(np.array(list(aminoacids))[s])
```




    'ATNIVPTENC'




```python
aas_arr = np.array(list(aminoacids))

```


```python
%%timeit
s = ''.join(np.random.choice(aas_arr, size=N))
```

    11.2 µs ± 67.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)



```python
%%timeit
s = aas_arr[np.random.randint(q, size=N)]
#s = ''.join(aas_arr[s])

```

    1.65 µs ± 52.5 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)



```python

```
#### maxent_analysis.ipynb



```python
import sys
sys.path.append('..')
import itertools, copy
import json
import numpy as np
import scipy.misc
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

from lib import *
import clib
```


```python
h = pd.read_csv('data/h.csv', index_col=0)
Jk = pd.read_csv('data/Jk.csv', index_col=0)
```


```python
q = len(aminoacids)
N = 9
jump = lambda x: np.random.randint(q, size=N)
x0 = jump(0)
samples = mcmcsampler(x0, lambda x: clib.energy(x, np.asarray(h).flatten(), np.asarray(Jk).reshape(3, q, q)), jump, 1e6)
```


```python
samples = [''.join(map_numbertoaa(s)) for s in samples]
```


```python
df0 = counter_to_df(count_kmers_proteome(human, 1))
df0 = df0.set_index('seq')
```


```python
dfm0 = df0.merge(counter_to_df(count_kmers_iterable(samples, 1)), left_index=True, right_on='seq')
x = np.linspace(0.0, 0.1)
plt.plot(x, x, 'k')
plt.scatter(dfm0['freq_x'], dfm0['freq_y'])
dfm0['logfold'] = np.log(dfm0['freq_x']/dfm0['freq_y'])
np.abs(dfm0['logfold']).mean()
```




    4.200506351760171




![png](notebook_files/maxent_analysis_5_1.png)



```python
df0
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>freq</th>
    </tr>
    <tr>
      <th>seq</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>M</th>
      <td>0.021328</td>
    </tr>
    <tr>
      <th>G</th>
      <td>0.065778</td>
    </tr>
    <tr>
      <th>A</th>
      <td>0.070127</td>
    </tr>
    <tr>
      <th>P</th>
      <td>0.063148</td>
    </tr>
    <tr>
      <th>L</th>
      <td>0.099708</td>
    </tr>
    <tr>
      <th>S</th>
      <td>0.083325</td>
    </tr>
    <tr>
      <th>W</th>
      <td>0.012173</td>
    </tr>
    <tr>
      <th>R</th>
      <td>0.056436</td>
    </tr>
    <tr>
      <th>V</th>
      <td>0.059638</td>
    </tr>
    <tr>
      <th>E</th>
      <td>0.071011</td>
    </tr>
    <tr>
      <th>Y</th>
      <td>0.026627</td>
    </tr>
    <tr>
      <th>C</th>
      <td>0.023051</td>
    </tr>
    <tr>
      <th>T</th>
      <td>0.053478</td>
    </tr>
    <tr>
      <th>D</th>
      <td>0.047316</td>
    </tr>
    <tr>
      <th>K</th>
      <td>0.057243</td>
    </tr>
    <tr>
      <th>I</th>
      <td>0.043301</td>
    </tr>
    <tr>
      <th>Q</th>
      <td>0.047670</td>
    </tr>
    <tr>
      <th>H</th>
      <td>0.026268</td>
    </tr>
    <tr>
      <th>F</th>
      <td>0.036530</td>
    </tr>
    <tr>
      <th>N</th>
      <td>0.035845</td>
    </tr>
  </tbody>
</table>
</div>




```python

```
#### maxent.ipynb



```python
import sys
sys.path.append('..')
import itertools, copy
import json
import numpy as np
import scipy.misc
from sklearn.model_selection import train_test_split
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

plt.style.use('../peptidome.mplstyle')

from lib import *
from base import *
```


```python
output = True
aas_arr = np.array(list(aminoacids))
N = 4
seed = 1234
prng = np.random.RandomState(seed)

```


```python
humanseqs = [s for s in fasta_iter(human, returnheader=False)]
train, test = train_test_split(humanseqs, test_size=0.5)

```


```python
# evaluate empirical observables for fitting
df0 = count(train, 1)
df1 = count(train, 2, gap=0)
dfgap1 = count(train, 2, gap=1)
dfgap2 = count(train, 2, gap=2)
```


```python
h, Jk = fit_ising(df0, [df1, dfgap1, dfgap2], nmcmc=1e6, niter=30, epsilon=0.1, prng=prng, output=output, N=N)
```

    [ 0.46011294 -0.66063989  0.05774567  0.46140263 -0.20088463  0.3939762
     -0.52393268 -0.03443961  0.24542297  0.80966027 -0.73823204 -0.21909044
      0.35340522  0.07413293  0.23697674  0.62224697  0.17656732  0.29459131
     -1.293836   -0.5151859 ]
    iteration 0
    f1 1.522898693065261e-06
    f2, gap 0 0.002389626857681986
    f2, gap 1 0.0017856040684536955
    f2, gap 2 0.0019484053973687473
    iteration 1
    f1 2.6668264323075684e-06
    f2, gap 0 0.0019948547852433425
    f2, gap 1 0.0014822126881021852
    f2, gap 2 0.0016161554791216917
    iteration 2
    f1 5.7016337530539066e-06
    f2, gap 0 0.0015874638556658662
    f2, gap 1 0.0010956632776655789
    f2, gap 2 0.0012546877479135536
    iteration 3
    f1 5.077489165198753e-06
    f2, gap 0 0.001287340720184847
    f2, gap 1 0.0009781249925279014
    f2, gap 2 0.001096773962313074
    iteration 4
    f1 5.754426891491868e-06
    f2, gap 0 0.001060822159517603
    f2, gap 1 0.0007836362950464884
    f2, gap 2 0.0009640595245758452
    iteration 5
    f1 4.855084364655073e-06
    f2, gap 0 0.0008568795047436233
    f2, gap 1 0.0006830886223097116
    f2, gap 2 0.000734461856976614
    iteration 6
    f1 4.747190011300455e-06
    f2, gap 0 0.0007513397589381338
    f2, gap 1 0.000539334622866687
    f2, gap 2 0.0007053553836563814
    iteration 7
    f1 5.008879638367439e-06
    f2, gap 0 0.000565154232799269
    f2, gap 1 0.0004087229883336073
    f2, gap 2 0.0006166102932030639
    iteration 8
    f1 4.928414357457274e-06
    f2, gap 0 0.00045715848602341643
    f2, gap 1 0.0004018110301031725
    f2, gap 2 0.00048720098201275266
    iteration 9
    f1 4.291871956961184e-06
    f2, gap 0 0.000388928058718351
    f2, gap 1 0.0003306049137955739
    f2, gap 2 0.00044909459782892187
    iteration 10
    f1 4.925157997322414e-06
    f2, gap 0 0.000327373594144109
    f2, gap 1 0.0002594932509868376
    f2, gap 2 0.00038119238498903813
    iteration 11
    f1 8.698005044593334e-06
    f2, gap 0 0.0002541262291681052
    f2, gap 1 0.00021897320523853113
    f2, gap 2 0.00029953840821310114
    iteration 12
    f1 5.736523007281051e-06
    f2, gap 0 0.00021302211855830927
    f2, gap 1 0.00019820998703339802
    f2, gap 2 0.0003155491125303814
    iteration 13
    f1 5.839856075795281e-06
    f2, gap 0 0.00022696165593136838
    f2, gap 1 0.00018681589060368017
    f2, gap 2 0.0002925456315989977
    iteration 14
    f1 7.255450452776314e-06
    f2, gap 0 0.00015594424843199756
    f2, gap 1 0.00016319830262789887
    f2, gap 2 0.0002585437678462777
    iteration 15
    f1 5.1721109801722946e-06
    f2, gap 0 0.0001507600718210587
    f2, gap 1 0.0001370720764680204
    f2, gap 2 0.00023880684753431285
    iteration 16
    f1 7.46476638241338e-06
    f2, gap 0 0.00012952229993380254
    f2, gap 1 0.00013629998013829685
    f2, gap 2 0.00023400100820275674
    iteration 17
    f1 5.362218402212592e-06
    f2, gap 0 0.00013304318309664587
    f2, gap 1 0.0001317032855524886
    f2, gap 2 0.0002107552439123478
    iteration 18
    f1 5.426533523226553e-06
    f2, gap 0 0.00011256792905417202
    f2, gap 1 0.00010890160250518578
    f2, gap 2 0.00018001494249667097
    iteration 19
    f1 5.225710351918192e-06
    f2, gap 0 8.987118515054653e-05
    f2, gap 1 0.00010265243709433594
    f2, gap 2 0.0001942580814817988
    iteration 20
    f1 7.300837758037412e-06
    f2, gap 0 8.175449786378476e-05
    f2, gap 1 8.811782635636024e-05
    f2, gap 2 0.00016737640128431242
    iteration 21
    f1 4.463639756015309e-06
    f2, gap 0 8.328219764667682e-05
    f2, gap 1 9.641941971846178e-05
    f2, gap 2 0.0001978111449609972
    iteration 22
    f1 5.85075805826556e-06
    f2, gap 0 9.740506846609546e-05
    f2, gap 1 0.00010731905021349065
    f2, gap 2 0.0001926209275246567
    iteration 23
    f1 8.191756307798523e-06
    f2, gap 0 7.26781214088918e-05
    f2, gap 1 0.00010724368544172522
    f2, gap 2 0.00016336699749016384
    iteration 24
    f1 8.133047952047157e-06
    f2, gap 0 6.475128844738058e-05
    f2, gap 1 8.354416330703384e-05
    f2, gap 2 0.00020202390874105437
    iteration 25
    f1 6.6961254186734715e-06
    f2, gap 0 7.420023781719748e-05
    f2, gap 1 0.00010263422363149512
    f2, gap 2 0.00019060229429013203
    iteration 26
    f1 7.532906455979948e-06
    f2, gap 0 7.42029514035831e-05
    f2, gap 1 9.42941164075559e-05
    f2, gap 2 0.00020214406552345398
    iteration 27
    f1 6.462002179431454e-06
    f2, gap 0 6.272135162489555e-05
    f2, gap 1 8.955918976593361e-05
    f2, gap 2 0.00017180916316246833
    iteration 28
    f1 6.148227249644181e-06
    f2, gap 0 7.49855129850806e-05
    f2, gap 1 9.797908924403847e-05
    f2, gap 2 0.00017157069653172389
    iteration 29
    f1 7.259272585972233e-06
    f2, gap 0 6.515633851760876e-05
    f2, gap 1 9.635939759819657e-05
    f2, gap 2 0.00015418057137341068



```python

```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>freq_train</th>
      <th>freq_test</th>
      <th>freq_test</th>
    </tr>
    <tr>
      <th>seq</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>AAAA</th>
      <td>3.975436e-04</td>
      <td>NaN</td>
      <td>3.831855e-04</td>
    </tr>
    <tr>
      <th>AAAC</th>
      <td>1.390013e-05</td>
      <td>NaN</td>
      <td>1.280794e-05</td>
    </tr>
    <tr>
      <th>AAAD</th>
      <td>2.762650e-05</td>
      <td>NaN</td>
      <td>2.526498e-05</td>
    </tr>
    <tr>
      <th>AAAE</th>
      <td>5.577426e-05</td>
      <td>NaN</td>
      <td>5.175812e-05</td>
    </tr>
    <tr>
      <th>AAAF</th>
      <td>2.832151e-05</td>
      <td>NaN</td>
      <td>2.193141e-05</td>
    </tr>
    <tr>
      <th>AAAG</th>
      <td>9.399961e-05</td>
      <td>NaN</td>
      <td>9.281371e-05</td>
    </tr>
    <tr>
      <th>AAAH</th>
      <td>1.737516e-05</td>
      <td>NaN</td>
      <td>1.561516e-05</td>
    </tr>
    <tr>
      <th>AAAI</th>
      <td>2.571524e-05</td>
      <td>NaN</td>
      <td>2.193141e-05</td>
    </tr>
    <tr>
      <th>AAAK</th>
      <td>3.110153e-05</td>
      <td>NaN</td>
      <td>3.438844e-05</td>
    </tr>
    <tr>
      <th>AAAL</th>
      <td>8.565953e-05</td>
      <td>NaN</td>
      <td>8.597111e-05</td>
    </tr>
    <tr>
      <th>AAAM</th>
      <td>1.720141e-05</td>
      <td>NaN</td>
      <td>1.614151e-05</td>
    </tr>
    <tr>
      <th>AAAN</th>
      <td>1.702766e-05</td>
      <td>NaN</td>
      <td>1.807148e-05</td>
    </tr>
    <tr>
      <th>AAAP</th>
      <td>6.567810e-05</td>
      <td>NaN</td>
      <td>7.333862e-05</td>
    </tr>
    <tr>
      <th>AAAQ</th>
      <td>3.996287e-05</td>
      <td>NaN</td>
      <td>3.965198e-05</td>
    </tr>
    <tr>
      <th>AAAR</th>
      <td>4.917170e-05</td>
      <td>NaN</td>
      <td>4.842454e-05</td>
    </tr>
    <tr>
      <th>AAAS</th>
      <td>7.940448e-05</td>
      <td>NaN</td>
      <td>7.263682e-05</td>
    </tr>
    <tr>
      <th>AAAT</th>
      <td>5.282048e-05</td>
      <td>NaN</td>
      <td>5.631985e-05</td>
    </tr>
    <tr>
      <th>AAAV</th>
      <td>7.158566e-05</td>
      <td>NaN</td>
      <td>6.579422e-05</td>
    </tr>
    <tr>
      <th>AAAW</th>
      <td>8.340076e-06</td>
      <td>NaN</td>
      <td>8.597111e-06</td>
    </tr>
    <tr>
      <th>AAAY</th>
      <td>1.546389e-05</td>
      <td>NaN</td>
      <td>1.561516e-05</td>
    </tr>
    <tr>
      <th>AACA</th>
      <td>1.112010e-05</td>
      <td>NaN</td>
      <td>1.263249e-05</td>
    </tr>
    <tr>
      <th>AACC</th>
      <td>3.127529e-06</td>
      <td>NaN</td>
      <td>2.982671e-06</td>
    </tr>
    <tr>
      <th>AACD</th>
      <td>5.038796e-06</td>
      <td>NaN</td>
      <td>7.018050e-06</td>
    </tr>
    <tr>
      <th>AACE</th>
      <td>7.992573e-06</td>
      <td>NaN</td>
      <td>8.246209e-06</td>
    </tr>
    <tr>
      <th>AACF</th>
      <td>4.517541e-06</td>
      <td>NaN</td>
      <td>5.263537e-06</td>
    </tr>
    <tr>
      <th>AACG</th>
      <td>1.181511e-05</td>
      <td>NaN</td>
      <td>1.157978e-05</td>
    </tr>
    <tr>
      <th>AACH</th>
      <td>5.560051e-06</td>
      <td>NaN</td>
      <td>3.509025e-06</td>
    </tr>
    <tr>
      <th>AACI</th>
      <td>5.560051e-06</td>
      <td>NaN</td>
      <td>3.859927e-06</td>
    </tr>
    <tr>
      <th>AACK</th>
      <td>4.517541e-06</td>
      <td>NaN</td>
      <td>4.737184e-06</td>
    </tr>
    <tr>
      <th>AACL</th>
      <td>1.650640e-05</td>
      <td>NaN</td>
      <td>1.193068e-05</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>YYWK</th>
      <td>8.687580e-07</td>
      <td>NaN</td>
      <td>3.509025e-07</td>
    </tr>
    <tr>
      <th>YYWL</th>
      <td>1.216261e-06</td>
      <td>NaN</td>
      <td>5.263537e-07</td>
    </tr>
    <tr>
      <th>YYWN</th>
      <td>6.950064e-07</td>
      <td>NaN</td>
      <td>7.018050e-07</td>
    </tr>
    <tr>
      <th>YYWP</th>
      <td>1.390013e-06</td>
      <td>NaN</td>
      <td>1.228159e-06</td>
    </tr>
    <tr>
      <th>YYWQ</th>
      <td>5.212548e-07</td>
      <td>NaN</td>
      <td>3.509025e-07</td>
    </tr>
    <tr>
      <th>YYWR</th>
      <td>1.737516e-07</td>
      <td>NaN</td>
      <td>7.018050e-07</td>
    </tr>
    <tr>
      <th>YYWS</th>
      <td>1.216261e-06</td>
      <td>NaN</td>
      <td>1.403610e-06</td>
    </tr>
    <tr>
      <th>YYWV</th>
      <td>5.212548e-07</td>
      <td>NaN</td>
      <td>1.052707e-06</td>
    </tr>
    <tr>
      <th>YYWW</th>
      <td>8.687580e-07</td>
      <td>NaN</td>
      <td>1.754512e-07</td>
    </tr>
    <tr>
      <th>YYWY</th>
      <td>6.950064e-07</td>
      <td>NaN</td>
      <td>3.509025e-07</td>
    </tr>
    <tr>
      <th>YYYA</th>
      <td>2.258771e-06</td>
      <td>NaN</td>
      <td>1.929964e-06</td>
    </tr>
    <tr>
      <th>YYYC</th>
      <td>1.737516e-06</td>
      <td>NaN</td>
      <td>3.509025e-07</td>
    </tr>
    <tr>
      <th>YYYD</th>
      <td>3.648783e-06</td>
      <td>NaN</td>
      <td>2.982671e-06</td>
    </tr>
    <tr>
      <th>YYYE</th>
      <td>2.953777e-06</td>
      <td>NaN</td>
      <td>2.105415e-06</td>
    </tr>
    <tr>
      <th>YYYF</th>
      <td>1.911267e-06</td>
      <td>NaN</td>
      <td>1.579061e-06</td>
    </tr>
    <tr>
      <th>YYYG</th>
      <td>2.258771e-06</td>
      <td>NaN</td>
      <td>2.631769e-06</td>
    </tr>
    <tr>
      <th>YYYH</th>
      <td>1.563764e-06</td>
      <td>NaN</td>
      <td>1.228159e-06</td>
    </tr>
    <tr>
      <th>YYYI</th>
      <td>2.085019e-06</td>
      <td>NaN</td>
      <td>2.105415e-06</td>
    </tr>
    <tr>
      <th>YYYK</th>
      <td>1.042510e-06</td>
      <td>NaN</td>
      <td>1.929964e-06</td>
    </tr>
    <tr>
      <th>YYYL</th>
      <td>1.911267e-06</td>
      <td>NaN</td>
      <td>3.509025e-06</td>
    </tr>
    <tr>
      <th>YYYM</th>
      <td>1.563764e-06</td>
      <td>NaN</td>
      <td>1.403610e-06</td>
    </tr>
    <tr>
      <th>YYYN</th>
      <td>1.911267e-06</td>
      <td>NaN</td>
      <td>2.631769e-06</td>
    </tr>
    <tr>
      <th>YYYP</th>
      <td>2.953777e-06</td>
      <td>NaN</td>
      <td>1.403610e-06</td>
    </tr>
    <tr>
      <th>YYYQ</th>
      <td>3.475032e-06</td>
      <td>NaN</td>
      <td>2.456317e-06</td>
    </tr>
    <tr>
      <th>YYYR</th>
      <td>1.737516e-06</td>
      <td>NaN</td>
      <td>2.631769e-06</td>
    </tr>
    <tr>
      <th>YYYS</th>
      <td>3.996287e-06</td>
      <td>NaN</td>
      <td>2.631769e-06</td>
    </tr>
    <tr>
      <th>YYYT</th>
      <td>2.606274e-06</td>
      <td>NaN</td>
      <td>8.772562e-07</td>
    </tr>
    <tr>
      <th>YYYV</th>
      <td>2.432522e-06</td>
      <td>NaN</td>
      <td>5.263537e-07</td>
    </tr>
    <tr>
      <th>YYYW</th>
      <td>6.950064e-07</td>
      <td>NaN</td>
      <td>8.772562e-07</td>
    </tr>
    <tr>
      <th>YYYY</th>
      <td>2.953777e-06</td>
      <td>NaN</td>
      <td>2.807220e-06</td>
    </tr>
  </tbody>
</table>
<p>157836 rows × 3 columns</p>
</div>




```python
k = 4
df4 = count(train, k)
df4 = df4.merge(count(test, k), right_index=True, left_index=True, suffixes=['_train', '_test'])
jsd_test = calc_jsd(df4['freq_train'], df4['freq_test'])
jsd_flat = calc_jsd(df4['freq_test'], np.ones_like(df4['freq_test']))
```


```python
with open('../../data/triplet-human.json', 'r') as f:
    tripletparams = json.load(f)
kmers = df4.index
df4['freq_ind'] = np.array([10**(loglikelihood_independent(s, **tripletparams)) for s in kmers])
df4['freq_mc'] = np.array([10**(loglikelihood_mc(s, **tripletparams)) for s in kmers])
df4['freq_tri'] = np.array([10**(loglikelihood_triplet(s, **tripletparams)) for s in kmers])
jsd_ind = calc_jsd(df4['freq_test'], df4['freq_ind'])
jsd_mc = calc_jsd(df4['freq_test'], df4['freq_mc'])
jsd_tri = calc_jsd(df4['freq_test'], df4['freq_tri'])
```


```python
q = len(aminoacids)
Z = np.exp(scipy.special.logsumexp([-clib.energy(np.array(s), h, Jk) for s in itertools.product(range(q), repeat=k)]))
df4['freq_maxent'] = np.exp([-clib.energy(map_aatonumber(s), h, Jk) for s in kmers])/Z
jsd_maxent = calc_jsd(df4['freq_test'], df4['freq_maxent'])
```


```python
print('flat', jsd_flat, 'ind', jsd_ind, 'mc', jsd_mc, 'model', jsd_maxent, 'tri', jsd_tri, 'test', jsd_test, )
```

    flat 0.11022413525881233 ind 0.019422543152563265 mc 0.013133736028236852 model 0.009155048901039988 tri 0.00870439210858727 test 0.007588070936076536



```python
q = len(aminoacids)
N = 4
nmcmc = 1e6
prng = np.random
def jump(x):
    return prng.randint(q, size=N)
def energy(x):
    return clib.energy(x, h, Jk)
x0 = jump(None)
samples = mcmcsampler(x0, energy, jump, nmcmc)
samples = [''.join(aas_arr[s]) for s in samples]
```


```python
dfm0 = df0.merge(count(samples, 1), left_index=True, right_index=True)
x = np.linspace(0.0, 0.1)
plt.plot(x, x, 'k')
plt.scatter(dfm0['freq_x'], dfm0['freq_y'])
dfm0['logfold'] = np.log(dfm0['freq_x']/dfm0['freq_y'])
np.abs(dfm0['logfold']).mean()
```




    0.005162126422964316




![png](notebook_files/maxent_11_1.png)



```python
dfm1 = df1.merge(count(samples, 2), left_index=True, right_index=True)
x = np.linspace(0.0, 0.11**2)
plt.plot(x, x, 'k')
plt.scatter(dfm1['freq_x'], dfm1['freq_y'])
dfm1['logfold'] = np.log(dfm1['freq_x']/dfm1['freq_y'])
np.abs(dfm1['logfold']).mean()
```




    0.01984155921791898




![png](notebook_files/maxent_12_1.png)



```python
dfmgap1 = dfgap1.merge(count(samples, 2, gap=1), left_index=True, right_index=True)
x = np.linspace(0.0, 0.11**2)
plt.plot(x, x, 'k')
plt.scatter(dfmgap1['freq_x'], dfmgap1['freq_y'])
dfmgap1['logfold'] = np.log(dfmgap1['freq_x']/dfmgap1['freq_y'])
np.abs(dfmgap1['logfold']).mean()
```




    0.02306294047711688




![png](notebook_files/maxent_13_1.png)



```python
dfmgap2 = dfgap2.merge(count(samples, 2, gap=2), left_index=True, right_index=True)
x = np.linspace(0.0, 0.11**2)
plt.plot(x, x, 'k')
plt.scatter(dfmgap2['freq_x'], dfmgap2['freq_y'])
dfmgap2['logfold'] = np.log(dfmgap2['freq_x']/dfmgap2['freq_y'])
np.abs(dfmgap2['logfold']).mean()
```




    0.03242584925616405




![png](notebook_files/maxent_14_1.png)



```python
fig, axes = plt.subplots(figsize=(3.8, 2.0), ncols=2, sharex=True, sharey=True)
ax = axes[0]
ax.scatter(df4['freq_maxent'], df4['freq_test'], s=0.5, label='maxent', alpha=.1)
ax.set_xlabel('maxent prediction')
ax.set_ylabel('test set')
ax = axes[1]
ax.scatter(df4['freq_train'], df4['freq_test'], s=0.5, label='train', alpha=.1)
ax.set_xlabel('training set')
ax.set_ylabel('test set')
x = np.logspace(-7, -3)
for ax in axes:
    ax.plot(x, x, 'k')
    ax.set_xlim(min(x), max(x))
    ax.set_ylim(min(x), max(x))
    #plt.legend()
    ax.set_xscale('log')
    ax.set_yscale('log')
fig.tight_layout()
fig.savefig('4mer-comparison.png', dpi=600)
```


![png](notebook_files/maxent_15_0.png)



```python
dfJk = [pd.DataFrame.from_dict(J) for J in Jk]
```


```python
fig, axes = plt.subplots(figsize=(20, 6), ncols=len(dfJk), sharex=True, sharey=True)
for i, dfJ in enumerate(dfJk):
    sns.heatmap(dfJ, vmin=-0.5, vmax=0.5, cmap='RdBu_r', ax=axes[i])
fig.tight_layout()
```


![png](notebook_files/maxent_17_0.png)



```python
k = 5
#kmers = list(itertools.product(aminoacids, repeat=k))
df = counter_to_df(count_kmers_proteome(human, k))
df = df[~df['seq'].str.contains('U|B|X|Z')]
df = df.set_index('seq')
kmers = df.index
exp = np.array([float(df.loc[''.join(s)]) for s in kmers])
Z = np.exp(scipy.special.logsumexp([-energy_ising(s, h, Jk) for s in itertools.product(aminoacids, repeat=k)]))
ising = np.exp([-energy_ising(s, h, Jk) for s in kmers])/Z
tri = np.array([10**(loglikelihood_triplet(s, **tripletparams)) for s in kmers])
mc = np.array([10**(loglikelihood_mc(s, **tripletparams)) for s in kmers])
ind = np.array([10**(loglikelihood_independent(s, **tripletparams)) for s in kmers])
rising = np.corrcoef(ising, exp)[1, 0]
rind = np.corrcoef(ind, exp)[1, 0]
rtri = np.corrcoef(tri, exp)[1, 0]
rtri, rising, np.corrcoef(mc, exp)[1, 0], rind
```




    (0.6698462989385501, 0.658764374383573, 0.5852676481182697, 0.5268749495340342)




```python
fig = plt.figure(figsize=(4, 4))
plt.scatter(ind, exp, s=1, label='independent, r=%1.2f'%rind)
#plt.scatter(mc, exp, s=1)
plt.scatter(tri, exp, s=1, label='tri, r=%1.2f'%rtri)
x = np.logspace(-7, -3)
plt.xlabel('predicted')
plt.ylabel('observed')
plt.plot(x, x, 'k')
plt.xlim(min(x), max(x))
plt.ylim(min(x), max(x))
plt.legend()
plt.xscale('log')
plt.yscale('log')
fig.tight_layout()
fig.savefig('plots/modelfits-4mer-tri.png', dpi=300)
```


```python
pd.DataFrame(index=[key for key in h], data=[h[key] for key in h], columns=['h'])
```


```python
plot_sorted(df['count'])
```




    [<matplotlib.lines.Line2D at 0x7f5d527eef60>]




![png](notebook_files/maxent_21_1.png)



```python
doublets = [''.join(s) for s in itertools.product(list(aminoacids), repeat=2)]
```


```python
df = pd.DataFrame(index=doublets, data=[Jk[0][s[0]][s[1]] for s in doublets], columns=['J0'])
for i in range(1, len(Jk)):
    df['J%g'%i] = [Jk[i][s[0]][s[1]] for s in doublets]
```


```python
from functools import reduce
```


```python
df
```


```python
reduce(lambda left,right: pd.merge(left,right, left_index=True, right_index=True), [pd.DataFrame.from_dict(
    {i+j: Jk[gap][i][j] for i in Jk[gap].keys() for j in Jk[gap][i].keys()},
    orient='index')
           for gap in range(len(Jk))])
```


```python
pd.merge?
```


```python

```
#### jsd.ipynb



```python
import sys, copy, itertools
sys.path.append('..')
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import scipy.stats
import seaborn as sns
import sklearn.manifold
from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar
import matplotlib.font_manager as fm

from lib import *
colors = matplotlib.rcParams['axes.prop_cycle'].by_key()['color']
```


```python
names = ['Human', 'Mouse', 'Vaccinia', 'InfluenzaB', 'InfluenzaA', 'CMV', 'HCV', 'HSV1',
       'DENV', 'HIV', 'EBV', 'Ebola', 'Ecoli', 'Tuberculosis', 'Listeria',
       'Burkholderia', 'Meningococcus', 'StrepA', 'Hpylori',
       'Lyme', 'Tetanus', 'Leprosy', 'Malaria', 'Chagas',
       'OnchocercaVolvulus']
```


```python
dfs = {}
for name in names:
    path = 'data/%s.csv'%name
    if os.path.exists(path):
        df = pd.read_csv(path)
        #df.set_index('seq', inplace=True)
        dfs[name] = df
```


```python
N = len(dfs)
distances_uniform = np.zeros(N)
distances = np.zeros((N, N))
for i, namei in enumerate(dfs):
    df1 = dfs[namei]
    f1 = df1['freq_maxent']
    f2 = np.ones_like(f1)
    distances_uniform[i] = calc_jsd(f1, f2)
    for j, namej in enumerate(dfs):
        df2 = dfs[namej]
        dfm = pd.merge(df1, df2, on='seq', suffixes=['_1', '_2'])
        f1, f2 = np.asarray(dfm['freq_maxent_1']), np.asarray(dfm['freq_maxent_2'])
        distances[i, j] = calc_jsd(f1, f2, base=2)
```


```python
names = list(dfs.keys())
fullnames = list(proteomes.loc[names]['fullname'])
```


```python
df = pd.DataFrame(distances, index=names, columns=names, copy=True)
```


```python
fig = plt.figure(figsize=(8, 6))
sns.heatmap(df)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f9d2314f160>




![png](notebook_files/jsd_6_1.png)



```python
type_to_color = {'virus' : colors[0],
                 'bacterium' : colors[1],
                 'parasite' : colors[2],
                 'vertebrate' : colors[3]
                }
```


```python
cond_distances = scipy.spatial.distance.squareform(0.5*(distances+distances.T))
Z = scipy.cluster.hierarchy.linkage(cond_distances, method='average', optimal_ordering=True)
typecolors = np.array([type_to_color[proteomes.loc[name]['type']] for  name in names])
cg = sns.clustermap(df*(9.0/4.0), row_linkage=Z, col_linkage=Z, cbar_kws=dict(label='JSD in bits'), figsize=(8, 8))
for label, color in zip(cg.ax_heatmap.get_yticklabels(), typecolors[cg.dendrogram_col.reordered_ind]):
    label.set_color(color)
for label, color in zip(cg.ax_heatmap.get_xticklabels(), typecolors[cg.dendrogram_row.reordered_ind]):
    label.set_color(color)
ax = cg.ax_col_dendrogram
for i, (type_, color) in enumerate(type_to_color.items()):
    ax.text(1.07, 0.7-i*0.12, type_, color=color, transform=cg.ax_col_dendrogram.transAxes)
```


![png](notebook_files/jsd_8_0.png)



```python
df = pd.DataFrame(distances, index=names, columns=names, copy=True)
df['Uniform'] = distances_uniform
df = df.append(pd.Series(distances_uniform, name='Uniform', index=names))
df.iloc[-1, -1] = 0.0
rand = np.random.RandomState(seed=5)
mds = sklearn.manifold.MDS(n_components=2, dissimilarity='precomputed',
                           n_init=20, max_iter=500,
                           random_state=rand)
transformed = mds.fit_transform(df*4.5)
```


```python
type_to_color = {'virus' : colors[0],
                 'bacterium' : colors[1],
                 'parasite' : colors[2],
                 'vertebrate' : colors[3],
                 'uniform' : colors[4]
                }

fig, ax = plt.subplots(figsize=(8, 8))

typecolors = [type_to_color[proteomes.loc[name]['type']] for name in names]
typecolors.append(type_to_color['uniform'])
ax.scatter(transformed[:, 0], transformed[:, 1], color=typecolors)
offsets = 0.01*np.ones(len(df.index))
for index in [1, 4, 13, 14, 15, 23]:
    offsets[index] = -0.02
for i, name in enumerate(df.index):
    ax.text(transformed[i, 0], transformed[i, 1]+offsets[i], name, ha='center', color=typecolors[i])
ax.set_aspect('equal')
ax.set_xticks([])
ax.set_yticks([])
sns.despine(fig, left=True, bottom=True)

for i, (type_, color) in enumerate(type_to_color.items()):
    ax.text(0.8, 0.9-i*0.025, type_, color=color, transform=ax.transAxes)

fontprops = fm.FontProperties(size=12)
scalebar = AnchoredSizeBar(ax.transData,
                           0.5, '0.5 bit', 'lower left', 
                           pad=0.5,
                           color='k',
                           frameon=False,
                           size_vertical=0.005,
                           label_top=True,
                           fontproperties=fontprops)

ax.add_artist(scalebar)
fig.tight_layout()
```


![png](notebook_files/jsd_10_0.png)



```python
uniform = df['Uniform']
human = df['Human']
ys = uniform[names]
xs = human[names]
fig, ax = plt.subplots(figsize=(6, 6))
ax.scatter(xs, ys, color=typecolors[:-1])
#offset=0.00
#for i, name in enumerate(names):
#    ax.text(xs[i], ys[i]+offset, name, ha='center', color=typecolors[i])
ax.plot([0, 0.3], [0, 0.3], 'k-')
ax.set_xlabel('JSD(proteome, human)')
ax.set_ylabel('JSD(proteome, uniform)')
ax.set_aspect('equal')
ax.set_xlim(-0.01, 0.3)
ax.set_ylim(-0.01, 0.3)
for i, (type_, color) in enumerate(type_to_color.items()):
    ax.text(0.8, 0.2-i*0.03, type_, color=color, transform=ax.transAxes)
sns.despine(fig)
fig.tight_layout()
fig.savefig('dist_human_uniform.svg')
```


![png](notebook_files/jsd_11_0.png)



```python

```
#### fitmaxent.py

```python
import itertools, json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

import sys
sys.path.append('..')
from lib import *
import clib
from base import *

output = True
aas_arr = np.array(list(aminoacids))
N = 4
for name, row in proteomes.iterrows():
    if name == 'Human':
    #if not os.path.exists('data/%s.csv' % name):
        print(name)
        seed = 1234
        prng = np.random.RandomState(seed)

        proteome = datadir + row['path']
        seqs = [s for s in fasta_iter(proteome, returnheader=False)]
        #train, test = train_test_split(seqs, test_size=0.5)
        train, test = seqs, seqs

        # evaluate empirical observables for fitting
        #df0 = count(train, 1)
        df0 = pseudocount_f1(train)
        #df1 = count(train, 2, gap=0)
        df1 = pseudocount_f2(train, 2, 0, df0) 
        #dfgap1 = count(train, 2, gap=1)
        dfgap1 = pseudocount_f2(train, 2, 1, df0) 
        #dfgap2 = count(train, 2, gap=2)
        dfgap2 = pseudocount_f2(train, 2, 2, df0) 

        print('fit')
        h, Jk = fit_ising(df0, [df1, dfgap1, dfgap2], nmcmc=1e5, niter=20, epsilon=0.1, prng=prng, output=output, N=N)

        print('compare on 4mers')
        k = 4
        df4 = count(train, k)

        #df4_count = count(test, k)
        kmers = [''.join(s) for s in itertools.product(aminoacids, repeat=k)]
        df4_test = pd.DataFrame.from_dict(dict(seq=kmers, count=np.ones(len(kmers))))
        df4_test.set_index('seq', inplace=True)
        df4_count = counter_to_df(count_kmers_iterable(test, k), norm=False)
        df4_count.set_index('seq', inplace=True)
        df4_test = df4_test.add(df4_count, fill_value=0.0)
        df4_test['freq'] = df4_test['count'] / np.sum(df4_test['count'])

        m, jsd_test = calc_logfold(df4, df4_test)
        jsd_flat = calc_jsd(df4_test['freq'], np.ones_like(df4_test['freq']))

        tripletparams = calc_tripletmodelparams(proteome)
        kmers = df4_test.index
        df4_test['freq_ind'] = np.array([10**(loglikelihood_independent(s, **tripletparams)) for s in kmers])
        df4_test['freq_mc'] = np.array([10**(loglikelihood_mc(s, **tripletparams)) for s in kmers])
        df4_test['freq_tri'] = np.array([10**(loglikelihood_triplet(s, **tripletparams)) for s in kmers])
        jsd_ind = calc_jsd(df4_test['freq'], df4_test['freq_ind'])
        jsd_mc = calc_jsd(df4_test['freq'], df4_test['freq_mc'])
        jsd_tri = calc_jsd(df4_test['freq'], df4_test['freq_tri'])

        q = len(aminoacids)
        Z = np.exp(scipy.special.logsumexp([-clib.energy(np.array(s), h, Jk) for s in itertools.product(range(q), repeat=k)]))
        df4_test['freq_maxent'] = np.exp([-clib.energy(map_aatonumber(s), h, Jk) for s in kmers])/Z
        jsd_maxent = calc_jsd(df4_test['freq'], df4_test['freq_maxent'])
        #nmcmc = 1e7
        #prng = np.random
        #def jump(x):
        #    return prng.randint(q, size=N)
        #def energy(x):
        #    return clib.energy(x, h, Jk)
        #x0 = jump(None)
        #samples = mcmcsampler(x0, energy, jump, nmcmc)
        #samples = [''.join(aas_arr[s]) for s in samples]
        #df4_model = count(samples, 4)
        #m, jsd_model = calc_logfold(df4_test, df4_model)
        print('4mer', 'test', jsd_test, 'maxent', jsd_maxent,
              'flat', jsd_flat, 'ind', jsd_ind, 'mc', jsd_mc, 'tri', jsd_tri)

        df4_test.to_csv('data/%s.csv' % name)

        print(h, Jk)
        save(name, h, Jk)

```
#### base.py

```python
import itertools

import sys
sys.path.append('..')
from lib import *
import clib

import numpy as np
import pandas as pd

def calc_logfold(df1, df2, **kwargs):
    default = dict(left_index=True, right_index=True)
    default.update(kwargs)
    m = df1.merge(df2, **default)
    m['logfold'] = np.log(m['freq_x']/m['freq_y'])
    jsd = calc_jsd(m['freq_x'], m['freq_y'])
    return m, jsd
 
def pseudocount_f1(iterable, factor=1.0):
    df = pd.DataFrame.from_dict(dict(seq=list(aminoacids), count=np.ones(len(aminoacids))*factor))
    df.set_index('seq', inplace=True)
    df_count = counter_to_df(count_kmers_iterable(iterable, 1), norm=False)
    df_count.set_index('seq', inplace=True)
    df = df.add(df_count, fill_value=0.0)
    df['freq'] = df['count'] / np.sum(df['count'])
    return df[['freq']]

def pseudocount_f2(iterable, k, gap, f1):
    "Use pseudocounts to regularize pair frequencies"
    kmers = [''.join(s) for s in itertools.product(aminoacids, repeat=k)]
    ind = np.array([float(f1.loc[s[0]] * f1.loc[s[1]]) for s in kmers])
    df = pd.DataFrame.from_dict(dict(seq=kmers, count=ind*len(aminoacids)**2))
    df.set_index('seq', inplace=True)
    df_count = counter_to_df(count_kmers_iterable(iterable, k, gap), norm=False)
    df_count.set_index('seq', inplace=True)
    df = df.add(df_count, fill_value=0.0)
    df['freq'] = df['count'] / np.sum(df['count'])
    return df[['freq']]

def count(seqs, *args, **kwargs):
    df = counter_to_df(count_kmers_iterable(seqs, *args, **kwargs))
    df = df.set_index('seq')
    df = df.sort_index()
    return df

def fit_ising(f1, f2s, niter=1, nmcmc=1e6, epsilon=0.1, Jk=None, prng=None, output=False, N=10):
    if prng is None:
        prng = np.random
    h = np.array(np.log(f1['freq']))
    h -= np.mean(h)
    if output:
        print(h)
    q = len(aminoacids)
    aas_arr = np.array(list(aminoacids))
    if Jk is None:
        Jk = np.zeros((N-1, q, q))
    for i in range(niter):
        if output:
            print('iteration %g'%i)
        def jump(x):
            return prng.randint(q, size=N)
        def energy(x):
            return clib.energy(x, h, Jk)
        x0 = jump(None)
        samples = mcmcsampler(x0, energy, jump, nmcmc, prng=prng)
        samples = [''.join(aas_arr[s]) for s in samples]
        f1_model = count(samples, 1)
        m, jsd = calc_logfold(f1, f1_model)
        m = m.sort_values('seq')
        h += np.asarray(m['logfold'])*epsilon
        if output:
            print('f1', jsd)
        for gap in range(len(f2s)):
            f2_model = count(samples, 2, gap=gap)
            m, jsd = calc_logfold(f2s[gap], f2_model)
            if output:
                print('f2, gap', gap, jsd)
            for idx, row in m.iterrows():
                logfold = row['logfold']
                aa1 = aatonumber(idx[0])
                aa2 = aatonumber(idx[1])
                Jk[gap, aa1, aa2] += logfold * epsilon
    return h, Jk

def save(name, h, Jk):
    aas_arr = np.array(list(aminoacids))
    dfh = pd.DataFrame(index=aas_arr, data=h, columns=['h'])
    #dfJk = pd.DataFrame(data=Jk, columns=range(len(Jk)))
    doublets = [''.join(s) for s in itertools.product(list(aminoacids), repeat=2)]
    dfJk = pd.DataFrame(index=doublets,
                        data=[Jk[0,aatonumber(s[0]),aatonumber(s[1])] for s in doublets],
                        columns=['J0'])
    for i in range(1, len(Jk)):
        dfJk['J%g'%i] = [Jk[i,aatonumber(s[0]),aatonumber(s[1])] for s in doublets]

    dfh.to_csv('data/%s_h.csv' % name)
    dfJk.to_csv('data/%s_Jk.csv' % name)

```
