{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import scipy.stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "plt.style.use('../peptidome.mplstyle')\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class memoized(object):\n",
    "    \"\"\"Decorator. Caches a function's return value each time it is called.\n",
    "    If called later with the same arguments, the cached value is returned\n",
    "    (not reevaluated).\n",
    "    \"\"\"\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.cache = {}\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        # if args is not Hashable we can't cache\n",
    "        # easier to ask for forgiveness than permission\n",
    "        try:\n",
    "            if args in self.cache:\n",
    "                return self.cache[args]\n",
    "            else:\n",
    "                value = self.func(*args)\n",
    "                self.cache[args] = value\n",
    "                return value\n",
    "        except TypeError:\n",
    "            return self.func(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "from io import StringIO\n",
    "@memoized\n",
    "def normalize_taxid(taxid, rank='species'):\n",
    "    'return species level taxon id'\n",
    "    if not taxid:\n",
    "        return ''\n",
    "    out = check_output('efetch -db taxonomy -id \"{taxid}\"  -format native -mode xml -json'.format(taxid=taxid), shell=True, text=True)\n",
    "    buffer = StringIO(out)\n",
    "    results = json.load(buffer)\n",
    "    if results['TaxaSet']['Taxon']['Rank'] == 'species':\n",
    "        print(taxid, 'is species')\n",
    "        return taxid\n",
    "    try:\n",
    "        print(taxid, len(results['TaxaSet']['Taxon']['LineageEx']['Taxon']))\n",
    "        ids = [level['TaxId'] for level in results['TaxaSet']['Taxon']['LineageEx']['Taxon'] if level['Rank'] == rank]\n",
    "    except (KeyError, TypeError):\n",
    "        return ''\n",
    "    if len(ids) == 0:\n",
    "        return ''\n",
    "    return ids[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_unirefproteome_as_df_path(datadir + 'human-viruses-uniref90.fasta')\n",
    "df['length'] = df['Sequence'].str.len()\n",
    "df.sort_values('length', ascending=False, inplace=True)\n",
    "df = df[~df['header'].str.contains('(Fragment)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TaxID_species'] = df['TaxID'].apply(normalize_taxid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_protein_name(header):\n",
    "    m = re.search('(?<=\\s).+(?=\\sn\\=)', header)\n",
    "    if m:\n",
    "         return m.group(0)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Protein name'] = df.apply(lambda row: parse_protein_name(row['header']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TaxID_species'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['TaxID_species']=='')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df['TaxID'].unique())), len(set(df['TaxID_species'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(df['TaxID_species'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_to_series(counter):\n",
    "    count_df = pd.DataFrame.from_dict(counter, orient='index', columns=['count'])\n",
    "    count_series = count_df.T.squeeze()\n",
    "    return count_series\n",
    "def fraction_multiple(series):\n",
    "    return np.sum(series[series>1])/np.sum(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 9\n",
    "filterlength = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_series = counter_to_series(count_kmers_iterable(df['Sequence'], k, clean=True))\n",
    "fraction_multiple(count_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered = df.groupby('TaxID_species').head(20)\n",
    "filtered = df.groupby(['TaxID_species', 'Protein name']).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_fasta(filtered, datadir+'human-viruses-uniref90-filtered.fasta',\n",
    "#            seqcolumn='Sequence', descriptioncolumn='header')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_series_filtered = counter_to_series(count_kmers_iterable(filtered['Sequence'], k, clean=True))\n",
    "fraction_multiple(count_series_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_series_filtered_unique = counter_to_series(\n",
    "                       count_kmers_iterable(\n",
    "                           filter_unique(filtered['Sequence'], k, filterlength),\n",
    "                           k)\n",
    "                       )\n",
    "fraction_multiple(count_series_filtered_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'all %e, filtered %e, unique %e'%(np.sum(df['Sequence'].str.len()),\n",
    "              np.sum(filtered['Sequence'].str.len()),\n",
    "              np.sum(count_series_filtered_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_series_filtered_unique.sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins, _ = plt.hist(count_series_filtered, log=True,\n",
    "                           bins=np.arange(0, count_series_filtered.max()+1, 1+count_series_filtered.max()//1000));\n",
    "plt.hist(count_series_filtered_unique, log=True, bins=bins);\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
