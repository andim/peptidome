{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import scipy.stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "plt.style.use('../peptidome.mplstyle')\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class memoized(object):\n",
    "    \"\"\"Decorator. Caches a function's return value each time it is called.\n",
    "    If called later with the same arguments, the cached value is returned\n",
    "    (not reevaluated).\n",
    "    \"\"\"\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.cache = {}\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        # if args is not Hashable we can't cache\n",
    "        # easier to ask for forgiveness than permission\n",
    "        try:\n",
    "            if args in self.cache:\n",
    "                return self.cache[args]\n",
    "            else:\n",
    "                value = self.func(*args)\n",
    "                self.cache[args] = value\n",
    "                return value\n",
    "        except TypeError:\n",
    "            return self.func(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "from io import StringIO\n",
    "@memoized\n",
    "def normalize_taxid(taxid, rank='species'):\n",
    "    'return species level taxon id'\n",
    "    if not taxid:\n",
    "        return ''\n",
    "    out = check_output('efetch -db taxonomy -id \"{taxid}\"  -format native -mode xml -json'.format(taxid=taxid), shell=True, text=True)\n",
    "    buffer = StringIO(out)\n",
    "    results = json.load(buffer)\n",
    "    if results['TaxaSet']['Taxon']['Rank'] == 'species':\n",
    "        print(taxid, 'is species')\n",
    "        return taxid\n",
    "    try:\n",
    "        print(taxid, len(results['TaxaSet']['Taxon']['LineageEx']['Taxon']))\n",
    "        ids = [level['TaxId'] for level in results['TaxaSet']['Taxon']['LineageEx']['Taxon'] if level['Rank'] == rank]\n",
    "    except (KeyError, TypeError):\n",
    "        return ''\n",
    "    if len(ids) == 0:\n",
    "        return ''\n",
    "    return ids[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amayer/anaconda3/envs/py3/lib/python3.8/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df = load_unirefproteome_as_df_path(datadir + 'human-viruses-uniref90.fasta')\n",
    "df['length'] = df['Sequence'].str.len()\n",
    "df.sort_values('length', ascending=False, inplace=True)\n",
    "df = df[~df['header'].str.contains('(Fragment)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11118 7\n",
      "290028 is species\n",
      "694003 is species\n",
      "2697049 12\n",
      "2509481 10\n",
      "11137 is species\n",
      "277944 is species\n",
      "1980521 is species\n",
      "1980519 is species\n",
      "10310 is species\n",
      "11051 7\n",
      "11079 is species\n",
      "11082 is species\n",
      "11072 is species\n",
      "64315 9\n",
      "59563 is species\n",
      "64320 is species\n",
      "11083 is species\n",
      "44024 is species\n",
      "11089 is species\n",
      "164416 is species\n",
      "38837 is species\n",
      "12637 is species\n",
      "10325 is species\n",
      "340907 is species\n",
      "10376 is species\n",
      "10298 is species\n",
      "10294 8\n",
      "11103 is species\n",
      "11108 11\n",
      "10335 is species\n",
      "37296 is species\n",
      "11034 is species\n",
      "2169701 is species\n",
      "11036 is species\n",
      "11019 7\n",
      "11029 is species\n",
      "37124 is species\n",
      "1554474 10\n",
      "59300 is species\n",
      "59301 is species\n",
      "194960 7\n",
      "11033 is species\n",
      "11020 is species\n",
      "688449 7\n",
      "11269 is species\n",
      "12103 7\n",
      "12104 9\n",
      "204711 9\n",
      "95341 7\n",
      "11572 8\n",
      "1979160 is species\n",
      "39744 9\n",
      "11158 7\n",
      "121791 is species\n",
      "63330 is species\n",
      "10359 is species\n",
      "11620 is species\n",
      "138950 is species\n",
      "12059 7\n",
      "186539 is species\n",
      "2169992 is species\n",
      "186538 is species\n",
      "2169991 is species\n",
      "11623 is species\n",
      "186540 is species\n",
      "11628 is species\n",
      "499556 is species\n"
     ]
    }
   ],
   "source": [
    "df['TaxID_species'] = df['TaxID'].apply(normalize_taxid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_protein_name(header):\n",
    "    m = re.search('(?<=\\s).+(?=\\sn\\=)', header)\n",
    "    if m:\n",
    "         return m.group(0)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Protein name'] = df.apply(lambda row: parse_protein_name(row['header']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TaxID_species'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['TaxID_species']=='')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df['TaxID'].unique())), len(set(df['TaxID_species'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(df['TaxID_species'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_to_series(counter):\n",
    "    count_df = pd.DataFrame.from_dict(counter, orient='index', columns=['count'])\n",
    "    count_series = count_df.T.squeeze()\n",
    "    return count_series\n",
    "def fraction_multiple(series):\n",
    "    return np.sum(series[series>1])/np.sum(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 9\n",
    "filterlength = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_series = counter_to_series(count_kmers_iterable(df['Sequence'], k, clean=True))\n",
    "fraction_multiple(count_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = df.groupby('TaxID_species').head(500)\n",
    "#filtered = df.groupby(['TaxID_species', 'Protein name']).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_fasta(filtered, datadir+'human-viruses-uniref90-filtered.fasta',\n",
    "#            seqcolumn='Sequence', descriptioncolumn='header')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_series_filtered = counter_to_series(count_kmers_iterable(filtered['Sequence'], k, clean=True))\n",
    "fraction_multiple(count_series_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_series_filtered_unique = counter_to_series(\n",
    "                       count_kmers_iterable(\n",
    "                           filter_unique(filtered['Sequence'], k, filterlength),\n",
    "                           k)\n",
    "                       )\n",
    "fraction_multiple(count_series_filtered_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'all %e, filtered %e, unique %e'%(np.sum(df['Sequence'].str.len()),\n",
    "              np.sum(filtered['Sequence'].str.len()),\n",
    "              np.sum(count_series_filtered_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_series_filtered_unique.sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins, _ = plt.hist(count_series_filtered, log=True,\n",
    "                           bins=np.arange(0, count_series_filtered.max()+1, 1+count_series_filtered.max()//1000));\n",
    "plt.hist(count_series_filtered_unique, log=True, bins=bins);\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
